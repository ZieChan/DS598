{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67CoRHqXVctX"
   },
   "source": [
    "# Homework 3: Exploration in RL (due 11:59PM, April 5th, 2024)\n",
    "\n",
    "In this homework, you will implement and compare a number of exploration strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (2 points)\n",
    "\n",
    "Implement a **combination lock MDP** of length H = 20, number of actions A = 10, number of states per step = 3. Denote the states as $\\{s_{h;1}, s_{h;2}, s_{h;3}\\}_{h=1:20}$. While initializing the MDP, uniformly randomly choose one out of ten actions for each stage as the **good action**, denoted as $\\{a^*_h\\}_{h=1:20}$. Define the transition as: \n",
    "\n",
    "$$P(s_{h+1;1}|s_{h;1},a^*_h)=P(s_{h+1;2}|s_{h;1},a^*_h)=P(s_{h+1;1}|s_{h;2},a^*_h)=P(s_{h+1;2}|s_{h;2},a^*_h)=0.5$$\n",
    "while for $a\\neq a^*_h$,\n",
    "$$P(s_{h+1;3}|s_{h;1},a)=P(s_{h+1;3}|s_{h;2},a)=P(s_{h+1;3}|s_{h;3},a)=1$$\n",
    "Lastly, if you are in the bad state, for any action $a$,\n",
    "$$P(s_{h+1;3}|s_{h;3},a)=1$$\n",
    "In terms of rewards, the agent receives a reward of 10 upon reaching $s_{H,1}$ or $s_{H,2}$, at which point the episode will also reset. Otherwise the reward will always be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h_dSFrzHVctZ",
    "outputId": "1fa71d66-2132-4052-e42b-5169455f8ea7"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class CombLockMDP(gym.Env):\n",
    "    \"\"\"\n",
    "    Methods:\n",
    "        reset(): Resets the environment to the starting state.\n",
    "        step(action): Takes a step in the environment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H=10, A=10, S=3, R=10, seed=0):\n",
    "        ## Fill in here\n",
    "        ## use the seed input as the random seed when generating the good actions.\n",
    "        \n",
    "        self.H=H\n",
    "        self.A = A  # Number of actions\n",
    "        self.S = S  # Number of states at each step\n",
    "        self.R = R  # Reward for reaching the good terminal state\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        ## Fill in here\n",
    "        \n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        ## Fill in here\n",
    "        \n",
    "        return self.state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: MultiDiscrete([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1])\n",
      "good: 5\n",
      "Initial state: 0\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "9\n",
      "1\n",
      "5\n",
      "4\n",
      "8\n",
      "7\n",
      "1\n",
      "6\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "5\n",
      "5\n",
      "8\n",
      "9\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "1\n",
      "6\n",
      "2\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "6\n",
      "3\n",
      "7\n",
      "0\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: True\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CombLockMDP(gym.Env):\n",
    "    \"\"\"\n",
    "    A combination lock MDP environment.\n",
    "    \n",
    "    Methods:\n",
    "        reset(): Resets the environment to the starting state.\n",
    "        step(action): Takes a step in the environment based on the action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H=20, A=10, S=3, R=10, seed=0):\n",
    "        # Set the random seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.H = H  # Number of steps in the episode\n",
    "        self.A = A  # Number of actions\n",
    "        self.S = S  # Number of states at each step\n",
    "        self.R = R  # Reward for reaching the good terminal state\n",
    "        self.all_states = []\n",
    "\n",
    "        # Initialize the action space and the observation space\n",
    "        self.action_space = gym.spaces.Discrete(self.A)\n",
    "        self.observation_space = gym.spaces.MultiDiscrete([1]*self.H)\n",
    "        print('observation_space:',self.observation_space)\n",
    "        \n",
    "        # Generate the good action. There is only 1 good action.\n",
    "        self.good_action = np.random.randint(self.A)\n",
    "        print('good:',self.good_action)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # Start at the first state\n",
    "        self.current_step = 0\n",
    "        self.state = 0 #random.randint(0,self.S-2)  # Initial state\n",
    "        self.all_states.append(self.state)\n",
    "        self.last_action_correct = True\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        reward = 0\n",
    "        if(self.done):\n",
    "            print(\"DONE\")\n",
    "            return self.state, reward, self.done\n",
    "\n",
    "        if self.state != (self.S - 1):\n",
    "            if action == self.good_action:\n",
    "                # Correct action\n",
    "                self.state = random.randint(0,self.S-2)\n",
    "            else:\n",
    "                self.state = self.S - 1\n",
    "                self.last_action_correct = False\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.all_states.append(self.state)\n",
    "        \n",
    "        if self.current_step >= self.H:\n",
    "            self.done = True  # End the episode after H steps\n",
    "            if self.state != self.S - 1:\n",
    "                reward = 10\n",
    "        return self.state, reward, self.done\n",
    "\n",
    "# Example usage:\n",
    "env = CombLockMDP()\n",
    "state = env.reset()\n",
    "print(f\"Initial state: {state}\")\n",
    "\n",
    "for i in range(50):\n",
    "    print(env.action_space.sample())\n",
    "\n",
    "for i in range(20):\n",
    "    #action == random.randint(0, 9)\n",
    "    action = env.action_space.sample()\n",
    "    current_state, reward, done = env.step(action)\n",
    "    print(f\"Current state: {current_state+1}, Reward: {reward}, Done: {done}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 0\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 9\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 9\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 7\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 1\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 1\n",
      "Initial state: 0\n",
      "Current state: 1, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 7\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 8\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 9\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 8\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 1\n",
      "Initial state: 0\n",
      "Current state: 2, Reward: 0, Done: False\n",
      "Current state: 2, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 7\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 7\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 1\n",
      "Initial state: 0\n",
      "Current state: 1, Reward: 0, Done: False\n",
      "Current state: 1, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 0\n",
      "Initial state: 1\n",
      "Current state: 1, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 8\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 2\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 6\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 3\n",
      "Initial state: 1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 4\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 1\n",
      "Initial state: 0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "Current state: 3, Reward: 0, Done: False\n"
     ]
    }
   ],
   "source": [
    "for j in range(50):\n",
    "    env = CombLockMDP(H=20, A=2, S=3, R=10, seed=j+50)\n",
    "    state = env.reset()\n",
    "    print(f\"Initial state: {state}\")\n",
    "    for i in range(3):\n",
    "        action = random.randint(0, 1)\n",
    "        #action = env.action_space.sample()\n",
    "        current_state, reward, done = env.step(action)\n",
    "        print(f\"Current state: {current_state+1}, Reward: {reward}, Done: {done}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "8\n",
      "5\n",
      "8\n",
      "1\n",
      "1\n",
      "8\n",
      "7\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "2\n",
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "4\n",
      "2\n",
      "9\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(np.random.randint(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good action: 6\n",
      "Episode 100 finished with reward: 0\n",
      "Episode 200 finished with reward: 0\n",
      "Episode 300 finished with reward: 0\n",
      "Episode 400 finished with reward: 0\n",
      "Episode 500 finished with reward: 0\n",
      "Episode 600 finished with reward: 0\n",
      "Episode 700 finished with reward: 0\n",
      "Episode 800 finished with reward: 0\n",
      "Episode 900 finished with reward: 0\n",
      "Episode 1000 finished with reward: 0\n",
      "Training complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHFCAYAAADi7703AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3E0lEQVR4nO3deXxU1f3/8feQhGyEYQlJiAYIBSE0oJJUTDRsati3okWWCEpVtOy2LIIF0YLQipQvi0IBv/1iBRVQqhjZESQsYogIEa0EwpLIIiRBJIHk/P7wx9QxySUDE5LB1/PxmMeDOfecO597Bpj3494zd2zGGCMAAACUqEpFFwAAAFCZEZYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJaAm4DNZivTY/Pmzdf1OpMnT5bNZrumsZs3b3ZLDdfz2lceXl5eCg0N1UMPPaT09HS3v97EiRNVr149eXt7q0aNGm7fP4Aby8bPnQCeb8eOHU7PX3jhBW3atEkbN250am/WrJmqV69+za9z7NgxHTt2THfffbfLY3Nzc3XgwIHrruFabN68We3atdPUqVPVrl07FRQU6NNPP9WUKVNUpUoV7du3T7fccotbXuu9995Tz549NWHCBHXq1Em+vr6KjY11y74BVAzvii4AwPX7eXipU6eOqlSpctVQc+HCBQUEBJT5dW699Vbdeuut11Rj9erVrylkuVPjxo0dNbRu3Vo1atTQ4MGD9frrr2vChAnXte8rc/nFF19IkoYPH66QkJDrrvmn+wZQMbgMB/xCtG3bVtHR0fr4448VHx+vgIAAPfbYY5Kk5cuXKzExUXXr1pW/v7+ioqI0btw4ff/99077KOkyXIMGDdS1a1clJyerZcuW8vf3V9OmTbV48WKnfiVdhhs0aJCqVaum//znP+rcubOqVaumiIgIPfPMM8rPz3caf+zYMT344IMKCgpSjRo11L9/f+3evVs2m02vv/76Nc3JleB05MgRR9vy5csVFxenwMBAVatWTR06dFBqaqrTuCt179u3T4mJiQoKCtJ9992nBg0aaOLEiZKk0NBQ2Ww2TZ48WZJUVFSkGTNmqGnTpvL19VVISIgeeeQRHTt2zGnfpb1Phw8fls1m01//+ldNnz5dDRo0kL+/v9q2bauvvvpKly5d0rhx4xQeHi673a5evXrp5MmTTvsu6/vsyvuSn5+vKVOmKCoqSn5+fqpdu7batWun7du3O/oYYzRv3jzdcccd8vf3V82aNfXggw/q0KFD1/CuATceYQn4BcnKytKAAQPUr18/rVmzRk8//bQk6euvv1bnzp21aNEiJScna+TIkXrrrbfUrVu3Mu03LS1NzzzzjEaNGqX33ntPLVq00ODBg/Xxxx9fdeylS5fUvXt33XfffXrvvff02GOP6ZVXXtH06dMdfb7//nu1a9dOmzZt0vTp0/XWW28pNDRUffr0ubaJ+P/+85//SPrxTJwkTZ06VX379lWzZs301ltv6f/+7/+Ul5enhIQEHThwwGlsQUGBunfvrvbt2+u9997T888/r1WrVmnw4MGSpOTkZKWkpOj3v/+9JOmpp57S2LFj9cADD2j16tV64YUXlJycrPj4eJ0+fdpp36W9T5I0d+5cffLJJ5o7d67+8Y9/6Msvv1S3bt00ePBgnTp1SosXL9aMGTO0fv16x2tf4cr7XJb35fLly+rUqZNeeOEFde3aVatWrdLrr7+u+Ph4ZWZmOvo9+eSTGjlypO6//369++67mjdvnvbv36/4+Hh9++23Lr9vwA1nANx0Bg4caAIDA53a2rRpYySZDRs2WI4tKioyly5dMlu2bDGSTFpammPbpEmTzM//26hfv77x8/MzR44ccbT98MMPplatWubJJ590tG3atMlIMps2bXKqU5J56623nPbZuXNn06RJE8fzuXPnGknmww8/dOr35JNPGklmyZIllsd05bWXL19uLl26ZC5cuGA+/vhj06hRI+Pl5WXS0tJMZmam8fb2NsOGDXMam5eXZ8LCwszvfve7YnUvXry42GtdmaNTp0452tLT040k8/TTTzv13blzp5Fknn32WUdbae9TRkaGkWRuv/12U1hY6GifNWuWkWS6d+/u1H/kyJFGksnJySlxTqze57K+L//85z+NJLNw4cISX8MYY1JSUowk8/LLLzu1Hz161Pj7+5sxY8aUOhaoLDizBPyC1KxZU+3bty/WfujQIfXr109hYWHy8vKSj4+P2rRpI0ll+rbYHXfcoXr16jme+/n56bbbbnO6vFUam81W7MxGixYtnMZu2bJFQUFB6tixo1O/vn37XnX/P9WnTx/5+PgoICBArVu3VmFhod555x21aNFCH330kS5fvqxHHnlEly9fdjz8/PzUpk2bEr/F17t37zK97qZNmyT9eHnrp+666y5FRUVpw4YNTu2lvU+S1LlzZ1Wp8t//uqOioiRJXbp0cep3pf2nZ3hceZ/L8r58+OGH8vPzc1zOLcn7778vm82mAQMGOM1rWFiYbr/99gr5diTgKhZ4A78gdevWLdZ2/vx5JSQkyM/PTy+++KJuu+02BQQE6OjRo/rtb3+rH3744ar7rV27drE2X1/fMo0NCAiQn59fsbEXL150PD9z5oxCQ0OLjS2pzcr06dPVvn17eXl5KTg4WBEREY5tVy4H/eY3vylx7E8DypW6y/qtvjNnzkgqef7Dw8OLhcqS+l1Rq1Ytp+dVq1a1bL8yj66+z2V5X06dOqXw8PBic/NT3377rYwxpb5XDRs2LHUsUFkQloBfkJLukbRx40adOHFCmzdvdpxlkKRz587dwMqs1a5dW7t27SrWnp2d7dJ+GjZsWOrX+IODgyVJ77zzjurXr3/Vfblyv6krYTIrK6vYtwlPnDjheO1r2XdZlcf7XKdOHW3btk1FRUWlBqbg4GDZbDZt3bpVvr6+xbaX1AZUNlyGA37hrnww//xD67XXXquIckrUpk0b5eXl6cMPP3RqX7Zsmdteo0OHDvL29tY333yj2NjYEh/X6soltaVLlzq17969W+np6brvvvuuq/ayKI/3uVOnTrp48aLltxG7du0qY4yOHz9e4pw2b978ml8fuFE4swT8wsXHx6tmzZoaMmSIJk2aJB8fH73xxhtKS0ur6NIcBg4cqFdeeUUDBgzQiy++qEaNGunDDz/URx99JKn4JbJr0aBBA02ZMkUTJkzQoUOH1LFjR9WsWVPffvutdu3apcDAQD3//PPXtO8mTZroiSee0P/8z/+oSpUq6tSpkw4fPqznnntOERERGjVq1HXXfzXl8T737dtXS5Ys0ZAhQ3Tw4EG1a9dORUVF2rlzp6KiovTwww/rnnvu0RNPPKFHH31Un376qVq3bq3AwEBlZWVp27Ztat68uZ566ik3HingfpxZAn7hateurQ8++EABAQEaMGCAHnvsMVWrVk3Lly+v6NIcAgMDtXHjRrVt21ZjxoxR7969lZmZqXnz5kmS235SZPz48XrnnXf01VdfaeDAgerQoYPGjBmjI0eOqHXr1te17/nz5+ull17SmjVr1LVrV02YMEGJiYnavn17iWu+3K083mdvb2+tWbNG48eP16pVq9SjRw898sgj2rZtm9OlzNdee01z5szRxx9/rIcfflhdunTRn//8Z33//fe666673HF4QLni504AeKypU6dq4sSJyszMvOY7iwPA1XAZDoBHmDNnjiSpadOmunTpkjZu3KjZs2drwIABBCUA5YqwBMAjBAQE6JVXXtHhw4eVn5+vevXqaezYsY6fFwGA8sJlOAAAAAss8AYAALBAWAIAALBAWAIAALDAAm83KCoq0okTJxQUFFQuP1MAAADczxijvLy8q/7GIWHJDU6cOOH0g5wAAMBzHD161PIWJIQlNwgKCpL042SX9VfIAQBAxcrNzVVERITjc7w0hCU3uHLprXr16oQlAAA8zNWW0LDAGwAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwILHhaV58+YpMjJSfn5+iomJ0datWy37b9myRTExMfLz81PDhg316quvltp32bJlstls6tmzp5urBgAAnsqjwtLy5cs1cuRITZgwQampqUpISFCnTp2UmZlZYv+MjAx17txZCQkJSk1N1bPPPqvhw4drxYoVxfoeOXJEf/zjH5WQkFDehwEAADyIzRhjKrqIsmrVqpVatmyp+fPnO9qioqLUs2dPTZs2rVj/sWPHavXq1UpPT3e0DRkyRGlpaUpJSXG0FRYWqk2bNnr00Ue1detWnTt3Tu+++26Z68rNzZXdbldOTo6qV69+bQcHAABuqLJ+fnvMmaWCggLt2bNHiYmJTu2JiYnavn17iWNSUlKK9e/QoYM+/fRTXbp0ydE2ZcoU1alTR4MHD3Z/4QAAwKN5V3QBZXX69GkVFhYqNDTUqT00NFTZ2dkljsnOzi6x/+XLl3X69GnVrVtXn3zyiRYtWqS9e/eWuZb8/Hzl5+c7nufm5pb9QAAAgEfxmDNLV9hsNqfnxphibVfrf6U9Ly9PAwYM0MKFCxUcHFzmGqZNmya73e54REREuHAEAADAk3jMmaXg4GB5eXkVO4t08uTJYmePrggLCyuxv7e3t2rXrq39+/fr8OHD6tatm2N7UVGRJMnb21sHDx7Ur371q2L7HT9+vEaPHu14npubS2ACAOAm5TFhqWrVqoqJidG6devUq1cvR/u6devUo0ePEsfExcXp3//+t1Pb2rVrFRsbKx8fHzVt2lT79u1z2j5x4kTl5eXp73//e6kByNfXV76+vtd5RAAAwBN4TFiSpNGjRyspKUmxsbGKi4vTggULlJmZqSFDhkj68YzP8ePH9c9//lPSj998mzNnjkaPHq3HH39cKSkpWrRokd58801Jkp+fn6Kjo51eo0aNGpJUrB0AAPwyeVRY6tOnj86cOaMpU6YoKytL0dHRWrNmjerXry9JysrKcrrnUmRkpNasWaNRo0Zp7ty5Cg8P1+zZs9W7d++KOgQAAOBhPOo+S5UV91kCAMDz3HT3WQIAAKgIhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALHheW5s2bp8jISPn5+SkmJkZbt2617L9lyxbFxMTIz89PDRs21Kuvvuq0feHChUpISFDNmjVVs2ZN3X///dq1a1d5HgIAAPAgHhWWli9frpEjR2rChAlKTU1VQkKCOnXqpMzMzBL7Z2RkqHPnzkpISFBqaqqeffZZDR8+XCtWrHD02bx5s/r27atNmzYpJSVF9erVU2Jioo4fP36jDgsAAFRiNmOMqegiyqpVq1Zq2bKl5s+f72iLiopSz549NW3atGL9x44dq9WrVys9Pd3RNmTIEKWlpSklJaXE1ygsLFTNmjU1Z84cPfLII2WqKzc3V3a7XTk5OapevbqLRwUAACpCWT+/PebMUkFBgfbs2aPExESn9sTERG3fvr3EMSkpKcX6d+jQQZ9++qkuXbpU4pgLFy7o0qVLqlWrlnsKBwAAHs27ogsoq9OnT6uwsFChoaFO7aGhocrOzi5xTHZ2don9L1++rNOnT6tu3brFxowbN0633HKL7r///lJryc/PV35+vuN5bm6uK4cCAAA8iMecWbrCZrM5PTfGFGu7Wv+S2iVpxowZevPNN7Vy5Ur5+fmVus9p06bJbrc7HhEREa4cAgAA8CAeE5aCg4Pl5eVV7CzSyZMni509uiIsLKzE/t7e3qpdu7ZT+9/+9jdNnTpVa9euVYsWLSxrGT9+vHJychyPo0ePXsMRAQAAT+AxYalq1aqKiYnRunXrnNrXrVun+Pj4EsfExcUV67927VrFxsbKx8fH0fbXv/5VL7zwgpKTkxUbG3vVWnx9fVW9enWnBwAAuDl5TFiSpNGjR+sf//iHFi9erPT0dI0aNUqZmZkaMmSIpB/P+Pz0G2xDhgzRkSNHNHr0aKWnp2vx4sVatGiR/vjHPzr6zJgxQxMnTtTixYvVoEEDZWdnKzs7W+fPn7/hxwcAACofj1ngLUl9+vTRmTNnNGXKFGVlZSk6Olpr1qxR/fr1JUlZWVlO91yKjIzUmjVrNGrUKM2dO1fh4eGaPXu2evfu7egzb948FRQU6MEHH3R6rUmTJmny5Mk35LgAAEDl5VH3WaqsuM8SAACe56a7zxIAAEBFICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABYICwBAABY8C5Lp88//7zMO2zRosU1FwMAAFDZlCks3XHHHbLZbDLGyGazWfYtLCx0S2EAAACVQZkuw2VkZOjQoUPKyMjQihUrFBkZqXnz5ik1NVWpqamaN2+efvWrX2nFihXlXS8AAMANVaYzS/Xr13f8+aGHHtLs2bPVuXNnR1uLFi0UERGh5557Tj179nR7kQAAABXF5QXe+/btU2RkZLH2yMhIHThwwC1FAQAAVBYuh6WoqCi9+OKLunjxoqMtPz9fL774oqKiotxaHAAAQEUr02W4n3r11VfVrVs3RURE6Pbbb5ckpaWlyWaz6f3333d7gQAAABXJZowxrg66cOGCli5dqi+//FLGGDVr1kz9+vVTYGBgedRY6eXm5sputysnJ0fVq1ev6HIAAEAZlPXz26UzS5cuXVKTJk30/vvv64knnrjuIgEAACo7l9Ys+fj4KD8//6r3WgIAALhZuLzAe9iwYZo+fbouX75cHvUAAABUKi4v8N65c6c2bNigtWvXqnnz5sXWKa1cudJtxQEAAFQ0l8NSjRo11Lt37/KoBQAAoNJxOSwtWbKkPOoAAAColFxeswQAAPBL4vKZJUl655139NZbbykzM1MFBQVO2z777DO3FAYAAFAZuHxmafbs2Xr00UcVEhKi1NRU3XXXXapdu7YOHTqkTp06lUeNAAAAFcblsDRv3jwtWLBAc+bMUdWqVTVmzBitW7dOw4cPV05OTnnUCAAAUGFcDkuZmZmKj4+XJPn7+ysvL0+SlJSUpDfffNO91QEAAFQwl8NSWFiYzpw5I0mqX7++duzYIUnKyMjQNfzMHAAAQKXmclhq3769/v3vf0uSBg8erFGjRumBBx5Qnz591KtXL7cXCAAAUJFsxsXTQUVFRSoqKpK3949fpHvrrbe0bds2NWrUSEOGDFHVqlXLpdDKrKy/WgwAACqPsn5+uxyWUBxhCQAAz1PWz2+X77N0zz33qE2bNmrbtq3uueeeYr8NBwAAcDNxec1S165d9dlnn+nBBx9UzZo1FRcXp3Hjxik5OVnnz58vjxoBAAAqzDVfhissLNTu3bu1efNmbd68WRs3bpTNZlN+fr67a6z0uAwHAIDnKbfLcFd8/fXXSktLU1pamj7//HNVr15dCQkJ17o7AACASsnlsNSnTx99/PHHKioqUuvWrdW6dWuNHz9eLVq0KI/6AAAAKpTLYentt99WcHCwBg0apHbt2ikhIUHVqlUrj9oAAAAqnMsLvL/77jv94x//0OXLlzVx4kQFBwerVatWGjt2rD788MPyqBEAAKDCXPd9lr755hu9+OKLWrp0qYqKilRYWOiu2jwGC7wBAPA85bbA+7vvvtOWLVsc34Lbv3+/atWqpR49eqhdu3bXVTQAAEBl43JYqlOnjoKDg5WQkKDHH39cbdu2VXR0dHnUBgAAUOFcDktpaWmEIwAA8Ivh8gLv6OhoXb58WevXr9drr72mvLw8SdKJEye4gzcAALjpuHxm6ciRI+rYsaMyMzOVn5+vBx54QEFBQZoxY4YuXryoV199tTzqBAAAqBAun1kaMWKEYmNjdfbsWfn7+zvae/XqpQ0bNri1OAAAgIrmcljatm2bJk6cqKpVqzq1169fX8ePH3dbYaWZN2+eIiMj5efnp5iYGG3dutWy/5YtWxQTEyM/Pz81bNiwxDNfK1asULNmzeTr66tmzZpp1apV5VU+AADwMC6HpdLupXTs2DEFBQW5pajSLF++XCNHjtSECROUmpqqhIQEderUSZmZmSX2z8jIUOfOnZWQkKDU1FQ9++yzGj58uFasWOHok5KSoj59+igpKUlpaWlKSkrS7373O+3cubNcjwUAAHgGl29K2adPH9ntdi1YsEBBQUH6/PPPVadOHfXo0UP16tXTkiVLyqtWtWrVSi1bttT8+fMdbVFRUerZs6emTZtWrP/YsWO1evVqpaenO9qGDBmitLQ0paSkOI4nNzfX6e7jHTt2VM2aNfXmm2+Wqa7yuCmlMUY/XPrl3eATAICS+Pt4yWazuXWf5XZTypkzZ6p9+/Zq1qyZLl68qH79+unrr79WcHBwmcPFtSgoKNCePXs0btw4p/bExERt3769xDEpKSlKTEx0auvQoYMWLVqkS5cuycfHRykpKRo1alSxPrNmzSq1lvz8fOXn5zue5+bmung0V/fDpUI1+/NHbt8vAACe6MCUDgqo6nJscQuXX/WWW27R3r17tWzZMu3Zs0dFRUUaPHiw+vfv77Tg291Onz6twsJChYaGOrWHhoYqOzu7xDHZ2dkl9r98+bJOnz6tunXrltqntH1K0rRp0/T8889f45EAAABP4lJYunTpkpo0aaL3339fjz76qB599NHyqqtUPz8FZ4yxPC1XUv+ft7u6z/Hjx2v06NGO57m5uYqIiLh68S7w9/HSgSkd3LpPAAA8lb+PV4W9tkthycfHR/n5+W6/ZlgWwcHB8vLyKnbG5+TJk8XODF0RFhZWYn9vb2/Vrl3bsk9p+5QkX19f+fr6XsthlJnNZquw040AAOC/XP423LBhwzR9+nRdvny5POopVdWqVRUTE6N169Y5ta9bt07x8fEljomLiyvWf+3atYqNjZWPj49ln9L2CQAAfllcPnWxc+dObdiwQWvXrlXz5s0VGBjotH3lypVuK+7nRo8eraSkJMXGxiouLk4LFixQZmamhgwZIunHy2PHjx/XP//5T0k/fvNtzpw5Gj16tB5//HGlpKRo0aJFTgvRR4wYodatW2v69Onq0aOH3nvvPa1fv17btm0rt+MAAACew+WwVKNGDfXu3bs8armqPn366MyZM5oyZYqysrIUHR2tNWvWqH79+pKkrKwsp3suRUZGas2aNRo1apTmzp2r8PBwzZ4926n++Ph4LVu2TBMnTtRzzz2nX/3qV1q+fLlatWp1w48PAABUPi7fZwnFlcd9lgAAQPkq6+e3y2uWAAAAfkkISwAAABYISwAAABYISwAAABYISwAAABbKdOuA2bNnl3mHw4cPv+ZiAAAAKpsy3TogMjKybDuz2XTo0KHrLsrTcOsAAAA8T1k/v8t0ZikjI8NthQEAAHgS1iwBAABYuKaftT927JhWr16tzMxMFRQUOG2bOXOmWwoDAACoDFwOSxs2bFD37t0VGRmpgwcPKjo6WocPH5YxRi1btiyPGgEAACqMy5fhxo8fr2eeeUZffPGF/Pz8tGLFCh09elRt2rTRQw89VB41AgAAVBiXw1J6eroGDhwoSfL29tYPP/ygatWqacqUKZo+fbrbCwQAAKhILoelwMBA5efnS5LCw8P1zTffOLadPn3afZUBAABUAi6vWbr77rv1ySefqFmzZurSpYueeeYZ7du3TytXrtTdd99dHjUCAABUGJfD0syZM3X+/HlJ0uTJk3X+/HktX75cjRo10iuvvOL2AgEAACpSme7gDWvcwRsAAM9T1s9vl9csNWzYUGfOnCnWfu7cOTVs2NDV3QEAAFRqLoelw4cPq7CwsFh7fn6+jh8/7paiAAAAKosyr1lavXq1488fffSR7Ha743lhYaE2bNigBg0auLU4AACAilbmsNSzZ09Jks1mc9xn6QofHx81aNBAL7/8sluLAwAAqGhlDktFRUWSpMjISO3evVvBwcHlVhQAAEBl4fKtAzIyMsqjDgAAgErJ5QXekrRlyxZ169ZNjRo1UuPGjdW9e3dt3brV3bUBAABUOJfD0tKlS3X//fcrICBAw4cP19ChQ+Xv76/77rtP//rXv8qjRgAAgArj8k0po6Ki9MQTT2jUqFFO7TNnztTChQuVnp7u1gI9ATelBADA85TbTSkPHTqkbt26FWvv3r0765kAAMBNx+WwFBERoQ0bNhRr37BhgyIiItxSFAAAQGVR5m/DPfbYY/r73/+uZ555RsOHD9fevXsVHx8vm82mbdu26fXXX9ff//738qwVAADghivzmiUvLy9lZWUpJCREq1at0ssvv+xYnxQVFaU//elP6tGjR7kWW1mxZgkAAM9T1s/vMp9Z+mmm6tWrl3r16nV9FQIAAHgAl9Ys2Wy28qoDAACgUnLpDt633XbbVQPTd999d10FAQAAVCYuhaXnn39edru9vGoBAACodFwKSw8//LBCQkLKqxYAAIBKp8xrllivBAAAfonKHJZc/FUUAACAm0KZL8MVFRWVZx0AAACVkss/dwIAAPBLQlgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACwQFgCAACw4DFh6ezZs0pKSpLdbpfdbldSUpLOnTtnOcYYo8mTJys8PFz+/v5q27at9u/f79j+3XffadiwYWrSpIkCAgJUr149DR8+XDk5OeV8NAAAwFN4TFjq16+f9u7dq+TkZCUnJ2vv3r1KSkqyHDNjxgzNnDlTc+bM0e7duxUWFqYHHnhAeXl5kqQTJ07oxIkT+tvf/qZ9+/bp9ddfV3JysgYPHnwjDgkAAHgAmzHGVHQRV5Oenq5mzZppx44datWqlSRpx44diouL05dffqkmTZoUG2OMUXh4uEaOHKmxY8dKkvLz8xUaGqrp06frySefLPG13n77bQ0YMEDff/+9vL29y1Rfbm6u7Ha7cnJyVL169Ws8SgAAcCOV9fPbI84spaSkyG63O4KSJN19992y2+3avn17iWMyMjKUnZ2txMRER5uvr6/atGlT6hhJjgmzCkr5+fnKzc11egAAgJuTR4Sl7OxshYSEFGsPCQlRdnZ2qWMkKTQ01Kk9NDS01DFnzpzRCy+8UOpZpyumTZvmWDtlt9sVERFRlsMAAAAeqELD0uTJk2Wz2Swfn376qSTJZrMVG2+MKbH9p36+vbQxubm56tKli5o1a6ZJkyZZ7nP8+PHKyclxPI4ePXq1QwUAAB6qbItyysnQoUP18MMPW/Zp0KCBPv/8c3377bfFtp06darYmaMrwsLCJP14hqlu3bqO9pMnTxYbk5eXp44dO6patWpatWqVfHx8LGvy9fWVr6+vZR8AAHBzqNCwFBwcrODg4Kv2i4uLU05Ojnbt2qW77rpLkrRz507l5OQoPj6+xDGRkZEKCwvTunXrdOedd0qSCgoKtGXLFk2fPt3RLzc3Vx06dJCvr69Wr14tPz8/NxwZAAC4WXjEmqWoqCh17NhRjz/+uHbs2KEdO3bo8ccfV9euXZ2+Cde0aVOtWrVK0o+X30aOHKmpU6dq1apV+uKLLzRo0CAFBASoX79+kn48o5SYmKjvv/9eixYtUm5urrKzs5Wdna3CwsIKOVYAAFC5VOiZJVe88cYbGj58uOPbbd27d9ecOXOc+hw8eNDphpJjxozRDz/8oKefflpnz55Vq1attHbtWgUFBUmS9uzZo507d0qSGjVq5LSvjIwMNWjQoByPCAAAeAKPuM9SZcd9lgAA8Dw31X2WAAAAKgphCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwILHhKWzZ88qKSlJdrtddrtdSUlJOnfunOUYY4wmT56s8PBw+fv7q23bttq/f3+pfTt16iSbzaZ3333X/QcAAAA8kseEpX79+mnv3r1KTk5WcnKy9u7dq6SkJMsxM2bM0MyZMzVnzhzt3r1bYWFheuCBB5SXl1es76xZs2Sz2cqrfAAA4KG8K7qAskhPT1dycrJ27NihVq1aSZIWLlyouLg4HTx4UE2aNCk2xhijWbNmacKECfrtb38rSfrf//1fhYaG6l//+peefPJJR9+0tDTNnDlTu3fvVt26dW/MQQEAAI/gEWeWUlJSZLfbHUFJku6++27Z7XZt3769xDEZGRnKzs5WYmKio83X11dt2rRxGnPhwgX17dtXc+bMUVhYWJnqyc/PV25urtMDAADcnDwiLGVnZyskJKRYe0hIiLKzs0sdI0mhoaFO7aGhoU5jRo0apfj4ePXo0aPM9UybNs2xdsputysiIqLMYwEAgGep0LA0efJk2Ww2y8enn34qSSWuJzLGXHWd0c+3/3TM6tWrtXHjRs2aNculusePH6+cnBzH4+jRoy6NBwAAnqNC1ywNHTpUDz/8sGWfBg0a6PPPP9e3335bbNupU6eKnTm64soltezsbKd1SCdPnnSM2bhxo7755hvVqFHDaWzv3r2VkJCgzZs3l7hvX19f+fr6WtYNAABuDhUaloKDgxUcHHzVfnFxccrJydGuXbt01113SZJ27typnJwcxcfHlzgmMjJSYWFhWrdune68805JUkFBgbZs2aLp06dLksaNG6ff//73TuOaN2+uV155Rd26dbueQwMAADcJj/g2XFRUlDp27KjHH39cr732miTpiSeeUNeuXZ2+Cde0aVNNmzZNvXr1ks1m08iRIzV16lQ1btxYjRs31tSpUxUQEKB+/fpJ+vHsU0mLuuvVq6fIyMgbc3AAAKBS84iwJElvvPGGhg8f7vh2W/fu3TVnzhynPgcPHlROTo7j+ZgxY/TDDz/o6aef1tmzZ9WqVSutXbtWQUFBN7R2AADguWzGGFPRRXi63Nxc2e125eTkqHr16hVdDgAAKIOyfn57xK0DAAAAKgphCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwIJ3RRdwMzDGSJJyc3MruBIAAFBWVz63r3yOl4aw5AZ5eXmSpIiIiAquBAAAuCovL092u73U7TZztTiFqyoqKtKJEycUFBQkm83mtv3m5uYqIiJCR48eVfXq1d22XxTHXN8YzPONwTzfOMz1jVFe82yMUV5ensLDw1WlSukrkziz5AZVqlTRrbfeWm77r169Ov8IbxDm+sZgnm8M5vnGYa5vjPKYZ6szSlewwBsAAMACYQkAAMACYakS8/X11aRJk+Tr61vRpdz0mOsbg3m+MZjnG4e5vjEqep5Z4A0AAGCBM0sAAAAWCEsAAAAWCEsAAAAWCEsAAAAWCEuV2Lx58xQZGSk/Pz/FxMRo69atFV2Sx5g2bZp+85vfKCgoSCEhIerZs6cOHjzo1McYo8mTJys8PFz+/v5q27at9u/f79QnPz9fw4YNU3BwsAIDA9W9e3cdO3bsRh6KR5k2bZpsNptGjhzpaGOe3ef48eMaMGCAateurYCAAN1xxx3as2ePYztzff0uX76siRMnKjIyUv7+/mrYsKGmTJmioqIiRx/m+dp8/PHH6tatm8LDw2Wz2fTuu+86bXfXvJ49e1ZJSUmy2+2y2+1KSkrSuXPnrq94g0pp2bJlxsfHxyxcuNAcOHDAjBgxwgQGBpojR45UdGkeoUOHDmbJkiXmiy++MHv37jVdunQx9erVM+fPn3f0eemll0xQUJBZsWKF2bdvn+nTp4+pW7euyc3NdfQZMmSIueWWW8y6devMZ599Ztq1a2duv/12c/ny5Yo4rEpt165dpkGDBqZFixZmxIgRjnbm2T2+++47U79+fTNo0CCzc+dOk5GRYdavX2/+85//OPow19fvxRdfNLVr1zbvv/++ycjIMG+//bapVq2amTVrlqMP83xt1qxZYyZMmGBWrFhhJJlVq1Y5bXfXvHbs2NFER0eb7du3m+3bt5vo6GjTtWvX66qdsFRJ3XXXXWbIkCFObU2bNjXjxo2roIo828mTJ40ks2XLFmOMMUVFRSYsLMy89NJLjj4XL140drvdvPrqq8YYY86dO2d8fHzMsmXLHH2OHz9uqlSpYpKTk2/sAVRyeXl5pnHjxmbdunWmTZs2jrDEPLvP2LFjzb333lvqdubaPbp06WIee+wxp7bf/va3ZsCAAcYY5tldfh6W3DWvBw4cMJLMjh07HH1SUlKMJPPll19ec71chquECgoKtGfPHiUmJjq1JyYmavv27RVUlWfLycmRJNWqVUuSlJGRoezsbKc59vX1VZs2bRxzvGfPHl26dMmpT3h4uKKjo3kffuYPf/iDunTpovvvv9+pnXl2n9WrVys2NlYPPfSQQkJCdOedd2rhwoWO7cy1e9x7773asGGDvvrqK0lSWlqatm3bps6dO0tinsuLu+Y1JSVFdrtdrVq1cvS5++67Zbfbr2vu+SHdSuj06dMqLCxUaGioU3toaKiys7MrqCrPZYzR6NGjde+99yo6OlqSHPNY0hwfOXLE0adq1aqqWbNmsT68D/+1bNkyffbZZ9q9e3exbcyz+xw6dEjz58/X6NGj9eyzz2rXrl0aPny4fH199cgjjzDXbjJ27Fjl5OSoadOm8vLyUmFhof7yl7+ob9++kvg7XV7cNa/Z2dkKCQkptv+QkJDrmnvCUiVms9mcnhtjirXh6oYOHarPP/9c27ZtK7btWuaY9+G/jh49qhEjRmjt2rXy8/MrtR/zfP2KiooUGxurqVOnSpLuvPNO7d+/X/Pnz9cjjzzi6MdcX5/ly5dr6dKl+te//qVf//rX2rt3r0aOHKnw8HANHDjQ0Y95Lh/umNeS+l/v3HMZrhIKDg6Wl5dXsRR88uTJYqkb1oYNG6bVq1dr06ZNuvXWWx3tYWFhkmQ5x2FhYSooKNDZs2dL7fNLt2fPHp08eVIxMTHy9vaWt7e3tmzZotmzZ8vb29sxT8zz9atbt66aNWvm1BYVFaXMzExJ/J12lz/96U8aN26cHn74YTVv3lxJSUkaNWqUpk2bJol5Li/umtewsDB9++23xfZ/6tSp65p7wlIlVLVqVcXExGjdunVO7evWrVN8fHwFVeVZjDEaOnSoVq5cqY0bNyoyMtJpe2RkpMLCwpzmuKCgQFu2bHHMcUxMjHx8fJz6ZGVl6YsvvuB9+P/uu+8+7du3T3v37nU8YmNj1b9/f+3du1cNGzZknt3knnvuKXb7i6+++kr169eXxN9pd7lw4YKqVHH+aPTy8nLcOoB5Lh/umte4uDjl5ORo165djj47d+5UTk7O9c39NS8NR7m6cuuARYsWmQMHDpiRI0eawMBAc/jw4YouzSM89dRTxm63m82bN5usrCzH48KFC44+L730krHb7WblypVm3759pm/fviV+TfXWW28169evN5999plp3779L/7rv1fz02/DGcM8u8uuXbuMt7e3+ctf/mK+/vpr88Ybb5iAgACzdOlSRx/m+voNHDjQ3HLLLY5bB6xcudIEBwebMWPGOPowz9cmLy/PpKammtTUVCPJzJw506SmpjpuieOuee3YsaNp0aKFSUlJMSkpKaZ58+bcOuBmNnfuXFO/fn1TtWpV07JlS8fX3nF1kkp8LFmyxNGnqKjITJo0yYSFhRlfX1/TunVrs2/fPqf9/PDDD2bo0KGmVq1axt/f33Tt2tVkZmbe4KPxLD8PS8yz+/z73/820dHRxtfX1zRt2tQsWLDAaTtzff1yc3PNiBEjTL169Yyfn59p2LChmTBhgsnPz3f0YZ6vzaZNm0r8f3ngwIHGGPfN65kzZ0z//v1NUFCQCQoKMv379zdnz569rtptxhhz7eelAAAAbm6sWQIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWALwi3X48GHZbDbt3bu33F5j0KBB6tmzZ7ntH0D5IywB8FiDBg2SzWYr9ujYsWOZxkdERCgrK0vR0dHlXCkAT+Zd0QUAwPXo2LGjlixZ4tTm6+tbprFeXl6OXzsHgNJwZgmAR/P19VVYWJjTo2bNmpIkm82m+fPnq1OnTvL391dkZKTefvttx9ifX4Y7e/as+vfvrzp16sjf31+NGzd2CmL79u1T+/bt5e/vr9q1a+uJJ57Q+fPnHdsLCws1evRo1ahRQ7Vr19aYMWP081+UMsZoxowZatiwofz9/XX77bfrnXfeKccZAnC9CEsAbmrPPfecevfurbS0NA0YMEB9+/ZVenp6qX0PHDigDz/8UOnp6Zo/f76Cg4MlSRcuXFDHjh1Vs2ZN7d69W2+//bbWr1+voUOHOsa//PLLWrx4sRYtWqRt27bpu+++06pVq5xeY+LEiVqyZInmz5+v/fv3a9SoURowYIC2bNlSfpMA4Ppc18/wAkAFGjhwoPHy8jKBgYFOjylTphhjjJFkhgwZ4jSmVatW5qmnnjLGGJORkWEkmdTUVGOMMd26dTOPPvpoia+1YMECU7NmTXP+/HlH2wcffGCqVKlisrOzjTHG1K1b17z00kuO7ZcuXTK33nqr6dGjhzHGmPPnzxs/Pz+zfft2p30PHjzY9O3b99onAkC5Ys0SAI/Wrl07zZ8/36mtVq1ajj/HxcU5bYuLiyv1229PPfWUevfurc8++0yJiYnq2bOn4uPjJUnp6em6/fbbFRgY6Oh/zz33qKioSAcPHpSfn5+ysrKcXs/b21uxsbGOS3EHDhzQxYsX9cADDzi9bkFBge68807XDx7ADUFYAuDRAgMD1ahRI5fG2Gy2Ets7deqkI0eO6IMPPtD69et133336Q9/+IP+9re/yRhT6rjS2n+uqKhIkvTBBx/olltucdpW1kXpAG481iwBuKnt2LGj2POmTZuW2r9OnToaNGiQli5dqlmzZmnBggWSpGbNmmnv3r36/vvvHX0/+eQTValSRbfddpvsdrvq1q3r9HqXL1/Wnj17HM+bNWsmX19fZWZmqlGjRk6PiIgIdx0yADfjzBIAj5afn6/s7GynNm9vb8fC7LfffluxsbG699579cYbb2jXrl1atGhRifv685//rJiYGP36179Wfn6+3n//fUVFRUmS+vfvr0mTJmngwIGaPHmyTp06pWHDhikpKUmhoaGSpBEjRuill15S48aNFRUVpZkzZ+rcuXOO/QcFBemPf/yjRo0apaKiIt17773Kzc3V9u3bVa1aNQ0cOLAcZgjA9SIsAfBoycnJqlu3rlNbkyZN9OWXX0qSnn/+eS1btkxPP/20wsLC9MYbb6hZs2Yl7qtq1aoaP368Dh8+LH9/fyUkJGjZsmWSpICAAH300UcaMWKEfvOb3yggIEC9e/fWzJkzHeOfeeYZZWVladCgQapSpYoee+wx9erVSzk5OY4+L7zwgkJCQjRt2jQdOnRINWrUUMuWLfXss8+6e2oAuInNmJ/dBAQAbhI2m02rVq3i50YAXBfWLAEAAFggLAEAAFhgzRKAmxarDAC4A2eWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALPw/FMjd8374uJUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CombLockMDP(gym.Env):\n",
    "    \"\"\"\n",
    "    A combination lock MDP environment.\n",
    "\n",
    "    Methods:\n",
    "        reset(): Resets the environment to the starting state.\n",
    "        step(action): Takes a step in the environment based on the action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H=20, A=10, S=3, R=10, seed=0):\n",
    "        # Set the random seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.H = H  # Number of steps in the episode\n",
    "        self.A = A  # Number of actions\n",
    "        self.S = S  # Number of states at each step\n",
    "        self.R = R  # Reward for reaching the good terminal state\n",
    "\n",
    "        # Initialize the action space and the observation space\n",
    "        self.action_space = gym.spaces.Discrete(self.A)\n",
    "        self.observation_space = gym.spaces.Discrete(self.S)\n",
    "\n",
    "        # There is only one good action for all states and steps\n",
    "        self.good_action = np.random.randint(self.A)\n",
    "        print(f'Good action: {self.good_action}')\n",
    "\n",
    "    def reset(self):\n",
    "        # Start at the first state\n",
    "        self.current_step = 0\n",
    "        # Set the initial state to be the first state\n",
    "        self.state = 0\n",
    "        self.last_action_correct = True\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"Invalid Action\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        if not self.done:\n",
    "            if self.last_action_correct:\n",
    "                if action == self.good_action:\n",
    "                    # Correct action, transition to next state\n",
    "                    self.state = (self.current_step + 1) % self.S\n",
    "                else:\n",
    "                    # Incorrect action, transition to bad state\n",
    "                    self.state = self.S - 1\n",
    "                    self.last_action_correct = False\n",
    "            else:\n",
    "                # Once in a bad state, always transition to the bad state\n",
    "                self.state = self.S - 1\n",
    "\n",
    "            # Update the current step\n",
    "            self.current_step += 1\n",
    "            if self.current_step >= self.H:\n",
    "                done = True  # End the episode after H steps\n",
    "                if self.state != self.S - 1:\n",
    "                    # Reward only if not in a bad state\n",
    "                    reward = self.R\n",
    "\n",
    "            self.done = done\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "# Example usage:\n",
    "env = CombLockMDP(H=20, A=10, S=3, R=10, seed=42)\n",
    "total_rewards = []\n",
    "\n",
    "num_episodes = 1000  # Number of episodes for training\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    for t in range(env.H):\n",
    "        # Randomly sample an action\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(episode_reward)\n",
    "    if (i_episode + 1) % 100 == 0:\n",
    "        print(f'Episode {i_episode + 1} finished with reward: {episode_reward}')\n",
    "\n",
    "print('Training complete')\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_value_iteration(env, gamma=0.9, threshold=0.0001):\n",
    "    \"\"\"\n",
    "    Run value iteration algorithm to find the optimal policy.\n",
    "\n",
    "    Args:\n",
    "    - env: The environment object.\n",
    "    - gamma: Discount factor.\n",
    "    - threshold: Threshold for value change to determine if iteration should stop.\n",
    "\n",
    "    Returns:\n",
    "    - policy: Optimal action for each state.\n",
    "    - value_table: Final table of state values.\n",
    "    \"\"\"\n",
    "    # Initialize value table specifically for CombLockMDP\n",
    "    # It's a one-dimensional table, where each state is represented by the timestep.\n",
    "    value_table = np.zeros(env.H)\n",
    "    # Policy is an array of actions to take at each timestep\n",
    "    policy = np.zeros(env.H, dtype=int)\n",
    "\n",
    "    while True:\n",
    "        updated_value_table = np.copy(value_table)\n",
    "\n",
    "        # For each state, perform the update\n",
    "        for state in range(env.H):\n",
    "            Q_values = []\n",
    "            \n",
    "            # For each action, calculate the Q-value\n",
    "            for action in range(env.A):\n",
    "                # Assume default transition for CombLockMDP (deterministic)\n",
    "                if state < env.H - 1:\n",
    "                    next_state = state + 1\n",
    "                else:\n",
    "                    next_state = state  # Terminal state\n",
    "\n",
    "                # Reward logic for CombLockMDP\n",
    "                reward = env.R if (state == env.H - 1 and action == env.good_action) else 0\n",
    "\n",
    "                # Calculate the Q-value\n",
    "                Q_value = reward + gamma * updated_value_table[next_state]\n",
    "                Q_values.append(Q_value)\n",
    "\n",
    "            # Select the best action based on max Q-value\n",
    "            best_action = np.argmax(Q_values)\n",
    "            value_table[state] = Q_values[best_action]\n",
    "            policy[state] = best_action\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.max(np.abs(updated_value_table - value_table)) < threshold:\n",
    "            break\n",
    "\n",
    "    return policy, value_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: MultiDiscrete([3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3])\n",
      "good: 5\n",
      "Optimal Policy:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]\n",
      "\n",
      "Value Table:\n",
      "[13.50768365 15.00863    16.67634817 18.52936836 20.58827968 22.87595893\n",
      " 25.41782476 28.24212012 31.38022608 34.86701049 38.74121538 43.04588748\n",
      " 47.82885648 53.14326648 59.04816648 65.60916648 72.89916648 80.99916648\n",
      " 89.99916648 99.99916648]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've defined CombLockMDP as before\n",
    "env = CombLockMDP(H=20, A=10, S=3, R=10, seed=1)\n",
    "optimal_policy, value_table = run_value_iteration(env)\n",
    "\n",
    "# Assuming the actions are still 0-9 and action env.good_action is the 'good' action\n",
    "print(\"Optimal Policy:\")\n",
    "print(optimal_policy)\n",
    "print(\"\\nValue Table:\")\n",
    "print(value_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yTjoCWGVcta"
   },
   "source": [
    "## Problem 2 (2 points)\n",
    "\n",
    "Implement the UCBVI algorithm with reward bonus $b_h(s,a)=\\alpha\\sqrt{1/N_h(s,a)}$, where $\\alpha$ is a hyperparameter that you will tune.\n",
    "\n",
    "Run UCBVI in the combination lock MDP (with turned $\\alpha$) and plot its learning curve: Cumulative reward v.s. training episode same as in HW2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBVI(object):\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        ## fill in other local parameters here\n",
    "\n",
    "    def update(self, state, action, next_state, reward, done):\n",
    "        ## fill in the local updates of UCBVI, including counts, \\hat{P} and reward bonus and value iteration, \n",
    "        ## for which you can keep track of a Q table Q_h(s,a).\n",
    "\n",
    "    def action(self, state):\n",
    "        ## fill in the excuted action, i.e. return argmax_a \\hat{Q}(s,a)      \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop: use a large enough num_episodes that make the algorithm converge.\n",
    "num_episodes = 1000000\n",
    "\n",
    "# Create an instance of the environment\n",
    "env = CombLockMDP()\n",
    "\n",
    "# Create an instance of UCBVI\n",
    "# remember to tune your alpha!!!\n",
    "\n",
    "agent = UCBVI(alpha) \n",
    "\n",
    "total_rewards = np.zeros(num_episodes)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    for h in range(env.H):\n",
    "        action = agent.action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_rewards[i_episode] += reward\n",
    "        agent.update(state,action,next_state,reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: MultiDiscrete([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1])\n",
      "good: 0\n",
      "Episode 0, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 100, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 200, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 300, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 400, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 500, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 600, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 700, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 800, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Episode 900, Total Reward: 10\n",
      "good_action 0\n",
      "action_list [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "class UCBVI(object):\n",
    "    def __init__(self, alpha=1, H=20, A=10, S=3):\n",
    "        self.alpha = alpha\n",
    "        self.H = H\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "\n",
    "        # Initialize counts, Q-values and U-values for upper confidence bounds\n",
    "        self.N = np.zeros((H, S, A)) # Count of visits to (state, action) pairs at each step\n",
    "        self.Q = np.ones((H, S, A)) # Q values\n",
    "        self.U = np.zeros((H, S, A)) # Upper confidence bounds\n",
    "\n",
    "        self.action_list = np.zeros(self.H)\n",
    "\n",
    "    def update(self, state, action, next_state, reward, done, step):\n",
    "        # Increment the visitation counts\n",
    "        self.N[step, state, action] += 1\n",
    "        \n",
    "        # Update Q value based on the received reward and the value of the next state\n",
    "        next_state_value = np.max(self.Q[step+1, next_state]) if step+1 < self.H else 0\n",
    "        alpha_n = 1 / self.N[step, state, action]\n",
    "        self.Q[step, state, action] += alpha_n * (reward + next_state_value - self.Q[step, state, action])\n",
    "        \n",
    "        # Update the bonus and the upper confidence bound (U) value\n",
    "        bonus = self.alpha * np.sqrt(1 / self.N[step, state, action])\n",
    "        self.U[step, state, action] = self.Q[step, state, action] + bonus\n",
    "\n",
    "    def action(self, state, step):\n",
    "        # Pick the action with the highest upper confidence bound at the current state\n",
    "        return np.argmax(self.U[step, state])\n",
    "\n",
    "# Create an instance of the environment\n",
    "env = CombLockMDP(H=5, A=3, S=3, R=10, seed=0)\n",
    "\n",
    "# Training loop: use a large enough num_episodes that make the algorithm converge.\n",
    "num_episodes = 1000  # Adjust this number as needed\n",
    "alpha = 1  # You'll need to tune this hyperparameter\n",
    "\n",
    "# Create an instance of UCBVI\n",
    "agent = UCBVI(alpha=alpha, H=env.H, A=env.A, S=env.S) \n",
    "\n",
    "total_rewards = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    for h in range(env.H):\n",
    "        action = agent.action(state, h)\n",
    "        agent.action_list[h] =  action\n",
    "        next_state, reward, done = env.step(action)\n",
    "        episode_reward += reward\n",
    "        agent.update(state, action, next_state, reward, done, h)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(episode_reward)\n",
    "    if i_episode % 100 == 0:\n",
    "        print(f'Episode {i_episode}, Total Reward: {episode_reward}')\n",
    "        print('good_action',env.good_action)\n",
    "        print('action_list',agent.action_list)\n",
    "\n",
    "print('Complete')\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 5\n",
      "Initial state: 0\n",
      "6\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "4\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "4\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "2\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "2\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "7\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "9\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "2\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "7\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "0\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "6\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "1\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "9\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "6\n",
      "Current state: 3, Reward: 0, Done: False\n",
      "8\n",
      "Current state: 3, Reward: 0, Done: True\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CombLockMDP(gym.Env):\n",
    "    \"\"\"\n",
    "    A combination lock MDP environment.\n",
    "    \n",
    "    Methods:\n",
    "        reset(): Resets the environment to the starting state.\n",
    "        step(action): Takes a step in the environment based on the action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, H=20, A=10, S=3, R=10, seed=0):\n",
    "        # Set the random seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.H = H  # Number of steps in the episode\n",
    "        self.A = A  # Number of actions\n",
    "        self.S = S  # Number of states at each step\n",
    "        self.R = R  # Reward for reaching the good terminal state\n",
    "        self.all_states = []\n",
    "\n",
    "        # Initialize the action space and the observation space\n",
    "        self.action_space = gym.spaces.Discrete(self.A)\n",
    "        self.observation_space = gym.spaces.MultiDiscrete([1]*self.H)\n",
    "        #print('observation_space:',self.observation_space)\n",
    "        \n",
    "        # Generate the good action. There is only 1 good action.\n",
    "        self.good_action = np.random.randint(self.A)\n",
    "        print('good:',self.good_action)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # Start at the first state\n",
    "        self.current_step = 0\n",
    "        self.state = 0 #random.randint(0,self.S-2)  # Initial state\n",
    "        self.all_states.append(self.state)\n",
    "        self.last_action_correct = True\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        reward = 0\n",
    "        if(self.done):\n",
    "            print(\"DONE\")\n",
    "            return self.state, reward, self.done\n",
    "\n",
    "        if self.state != (self.S - 1):\n",
    "            if action == self.good_action:\n",
    "                # Correct action\n",
    "                self.state = np.random.randint(0,self.S-1)\n",
    "            else:\n",
    "                self.state = self.S - 1\n",
    "                self.last_action_correct = False\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.all_states.append(self.state)\n",
    "        \n",
    "        if self.current_step >= self.H:\n",
    "            self.done = True  # End the episode after H steps\n",
    "            if self.state != self.S - 1:\n",
    "                reward = 10\n",
    "        return self.state, reward, self.done\n",
    "\n",
    "# Example usage:\n",
    "env = CombLockMDP()\n",
    "state = env.reset()\n",
    "print(f\"Initial state: {state}\")\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    #action == random.randint(0, 9)\n",
    "    action = env.action_space.sample()\n",
    "    print(action)\n",
    "    current_state, reward, done = env.step(action)\n",
    "    print(f\"Current state: {current_state+1}, Reward: {reward}, Done: {done}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 0\n",
      "Episode 1000: Total Reward: 0\n",
      "[3, 1, 0, 2, 2]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "9.0\n",
      "Episode 2000: Total Reward: 0\n",
      "[3, 3, 2, 3, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "8.1\n",
      "Episode 3000: Total Reward: 0\n",
      "[3, 1, 3, 3, 2]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "7.289999999999999\n",
      "Episode 4000: Total Reward: 0\n",
      "[3, 3, 1, 0, 2]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "6.560999999999999\n",
      "Episode 5000: Total Reward: 0\n",
      "[3, 1, 2, 0, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "5.9049\n",
      "Episode 6000: Total Reward: 0\n",
      "[3, 3, 3, 0, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "5.31441\n",
      "Episode 7000: Total Reward: 0\n",
      "[3, 1, 1, 0, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "4.782969\n",
      "Episode 8000: Total Reward: 0\n",
      "[3, 3, 2, 1, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "4.3046720999999994\n",
      "Episode 9000: Total Reward: 0\n",
      "[3, 1, 3, 1, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "3.8742048899999997\n",
      "Episode 10000: Total Reward: 0\n",
      "[3, 3, 1, 2, 3]\n",
      "[0, 2, 2, 2, 2, 2]\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "class UCBVI:\n",
    "    def __init__(self, H, A, S, alpha=1):\n",
    "        self.H = H\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "        self.alpha = alpha\n",
    "        self.Q = np.full((H, S, A), 10, dtype=np.float32)  # Optimistic initialization\n",
    "        self.V = np.zeros((H+1), dtype=np.float32)\n",
    "        self.N = np.zeros((H, S, A), dtype=np.int32)  # State-action counts\n",
    "        self.N_sas = np.zeros((H, S, A, S), dtype=np.int32)  # State-action-next-state counts\n",
    "        self.P_hat = np.zeros((H, S, A, S), dtype=np.float32)  # Empirical transition probabilities\n",
    "        self.D = []  # Dataset of experiencesself.N = np.zeros((H, A), dtype=np.int32)  # State-action counts\n",
    "# self.N_sas and self.P_hat might not be necessary for a deterministic MDP like CombLockMDP\n",
    "        self.steps=0\n",
    "\n",
    "    def update(self, h, s, a, next_s, r):\n",
    "        self.N[h, s, a] += 1\n",
    "        self.N_sas[h, s, a, next_s] += 1\n",
    "        \n",
    "        # Empirical transition probabilities for the observed next state\n",
    "        self.P_hat[h, s, a] = self.N_sas[h, s, a] / np.sum(self.N_sas[h, s, a])\n",
    "        \n",
    "        # Calculate the Q-value for state s and action a\n",
    "        q_value_update = r + np.dot(self.P_hat[h, s, a], self.V[h+1]) + self.bonus(h, s, a)\n",
    "        \n",
    "        # Update the Q-value if the new Q-value is less than the current one\n",
    "        self.Q[h, s, a] = np.min(np.append(q_value_update, self.Q[h, s, a]))\n",
    "    \n",
    "        # Update the value function for state s\n",
    "        self.V[h] = np.max(self.Q[h, s])\n",
    "        \n",
    "        if self.steps==1000:\n",
    "            self.steps=0\n",
    "            self.alpha=self.alpha-self.alpha*0.1\n",
    "            print(self.alpha)\n",
    "\n",
    "\n",
    "    def bonus(self, h, s, a):\n",
    "        return self.alpha * np.sqrt(1 / (1 + self.N[h, s, a]))\n",
    "\n",
    "    def action(self, h, s):\n",
    "        return np.argmax(self.Q[h, s] + self.bonus(h, s, np.arange(self.A)))\n",
    "\n",
    "# Assuming CombLockMDP is defined and imported properly\n",
    "env = CombLockMDP(H=5, A=4, S=3, R=10, seed=0)\n",
    "\n",
    "K = 10000  # Total episodes\n",
    "alpha = 10  # Confidence interval parameter\n",
    "agent = UCBVI(H=env.H, A=env.A, S=env.S,alpha=alpha)\n",
    "\n",
    "total_rewards = []\n",
    "#print(agent.Q)\n",
    "\n",
    "for k in range(K):\n",
    "    s = env.reset()\n",
    "    episode_reward = 0\n",
    "    action_list=[]\n",
    "    state_list=[s]\n",
    "    for h in range(env.H):\n",
    "        a = agent.action(h, s)\n",
    "        action_list.append(a)\n",
    "        #print(a)\n",
    "        next_s, r, done = env.step(a)\n",
    "        episode_reward += r\n",
    "        agent.update(h, s, a, next_s, r)\n",
    "        s = next_s\n",
    "        state_list.append(s)\n",
    "        if done:\n",
    "            #print(agent.Q)\n",
    "            agent.steps+=1\n",
    "            break\n",
    "    total_rewards.append(episode_reward)\n",
    "    if (k + 1) % 1000 == 0:\n",
    "        print(f'Episode {k + 1}: Total Reward: {episode_reward}')\n",
    "        print(action_list)\n",
    "        print(state_list)\n",
    "\n",
    "print('Complete')\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ]],\n",
       "\n",
       "       [[ 0.05478405,  0.05478405,  0.05478405,  0.05478405,\n",
       "          0.05478405,  0.05478405,  0.05478405,  0.05478405,\n",
       "          0.05478953,  0.05478953],\n",
       "        [ 0.05477858,  0.05477858,  0.05478405,  0.05478405,\n",
       "          0.05478405,  0.05478405,  0.05478405,  0.05478405,\n",
       "          0.05478405,  0.05478405],\n",
       "        [ 0.01291394,  0.01291394,  0.01291394,  0.01291394,\n",
       "          0.01291394,  0.01291394,  0.01291394,  0.01291394,\n",
       "          0.01291394,  0.01291394]],\n",
       "\n",
       "       [[ 0.17274226,  0.17274226,  0.17291422,  0.17291422,\n",
       "          0.17291422,  0.17291422,  0.17291422,  0.17291422,\n",
       "          0.17291422,  0.17291422],\n",
       "        [ 0.1732597 ,  0.1732597 ,  0.1732597 ,  0.1732597 ,\n",
       "          0.1732597 ,  0.1732597 ,  0.1732597 ,  0.1732597 ,\n",
       "          0.17343323,  0.17343323],\n",
       "        [ 0.01231297,  0.01231297,  0.01231297,  0.01231297,\n",
       "          0.01231297,  0.01231297,  0.01231297,  0.01231297,\n",
       "          0.01231297,  0.01231297]],\n",
       "\n",
       "       [[ 0.5424972 ,  0.5478953 ,  0.5478953 ,  0.5478953 ,\n",
       "          0.5478953 ,  0.5478953 ,  0.5478953 ,  0.5478953 ,\n",
       "          0.5478953 ,  0.5478953 ],\n",
       "        [ 0.5372555 ,  0.5372555 ,  0.5372555 ,  0.5372555 ,\n",
       "          0.5372555 ,  0.5372555 ,  0.5372555 ,  0.5372555 ,\n",
       "          0.5372555 ,  0.5424972 ],\n",
       "        [ 0.01225738,  0.01225738,  0.01225738,  0.01225738,\n",
       "          0.01225738,  0.01225738,  0.01225738,  0.01225738,\n",
       "          0.01225738,  0.01225738]],\n",
       "\n",
       "       [[ 1.4643118 ,  1.4643118 ,  1.757375  ,  1.757375  ,\n",
       "          1.757375  ,  1.757375  ,  1.757375  ,  1.757375  ,\n",
       "          1.5816375 ,  1.5816375 ],\n",
       "        [ 1.757375  ,  1.757375  ,  1.5816375 ,  1.5816375 ,\n",
       "          1.5816375 ,  1.5816375 ,  1.5816375 ,  1.5816375 ,\n",
       "          2.1390088 ,  1.9251078 ],\n",
       "        [ 0.01225186,  0.01225186,  0.01225186,  0.01225186,\n",
       "          0.01225186,  0.01225186,  0.01225186,  0.01225186,\n",
       "          0.01225186,  0.01225186]],\n",
       "\n",
       "       [[ 5.727565  ,  5.1548085 ,  3.7578554 ,  3.3820698 ,\n",
       "          2.7394764 , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 7.071068  ,  6.363961  ,  4.6393275 ,  4.175395  ,\n",
       "          3.0438628 , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225131,  0.01225131,  0.01225131,  0.01225131,\n",
       "          0.01225131,  0.01225131,  0.01225131,  0.01225131,\n",
       "          0.01225131,  0.01225131]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]],\n",
       "\n",
       "       [[10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        , 10.        , 10.        ,\n",
       "         10.        , 10.        ],\n",
       "        [ 0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125,  0.01225125,  0.01225125,\n",
       "          0.01225125,  0.01225125]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHFCAYAAADi7703AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA84klEQVR4nO3dd3hUZf7//9ekJ5QQCSShhk4QRcqCRENTQlEQ1oIgRUEEXUVAliIoRQVhFViWoosgX3ZRQRRFBQQXEhBCNRQh4i4EIpJQJQnFEJL79wc/5uOY5JAJmSQTn4/rmuty7rnvc97nHmRe3OfMGZsxxggAAAC58ijuAgAAAEoywhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhJQCthstnw9YmJibmk/kyZNks1mK9DYmJiYQqnhVvZ94+Hp6amQkBA9+uijSkhIKPT9TZgwQTVq1JCXl5cqVKhQ6NsHULRs/NwJ4P62b9/u8Py1117Tpk2btHHjRof2Ro0aqXz58gXez4kTJ3TixAndfffdTo9NS0vToUOHbrmGgoiJiVH79u01depUtW/fXlevXtXu3bs1ZcoUeXh46MCBA6patWqh7Ovzzz9Xjx49NH78eHXp0kW+vr5q0aJFoWwbQPHwKu4CANy634eXSpUqycPD46ah5vLlywoICMj3fqpVq6Zq1aoVqMby5csXKGQVpnr16tlraNOmjSpUqKBBgwZpyZIlGj9+/C1t+8Zcfv/995KkYcOGqXLlyrdc82+3DaB4cBoO+INo166dGjdurM2bNysyMlIBAQEaOHCgJGn58uWKjo5WWFiY/P39FRERobFjx+rSpUsO28jtNFx4eLgefPBBrVu3Ts2aNZO/v78aNmyoxYsXO/TL7TTck08+qbJly+p///ufunbtqrJly6p69ep66aWXlJGR4TD+xIkTeuSRR1SuXDlVqFBBTzzxhHbt2iWbzaYlS5YUaE5uBKfjx4/b25YvX67WrVurTJkyKlu2rDp16qT4+HiHcTfqPnDggKKjo1WuXDndd999Cg8P14QJEyRJISEhstlsmjRpkiQpOztbM2bMUMOGDeXr66vKlSurf//+OnHihMO283qfjh07JpvNpr/97W+aPn26wsPD5e/vr3bt2unHH39UZmamxo4dqypVqigwMFA9e/bU6dOnHbad3/fZmfclIyNDU6ZMUUREhPz8/FSxYkW1b99e27Zts/cxxmj+/Pm666675O/vr6CgID3yyCM6evRoAd41oOgRloA/kOTkZPXt21d9+vTRmjVr9Nxzz0mS/vvf/6pr165atGiR1q1bp+HDh2vFihXq1q1bvra7b98+vfTSSxoxYoQ+//xz3XnnnRo0aJA2b95807GZmZnq3r277rvvPn3++ecaOHCgZs2apenTp9v7XLp0Se3bt9emTZs0ffp0rVixQiEhIerVq1fBJuL/97///U/S9ZU4SZo6dap69+6tRo0aacWKFfrXv/6l9PR0RUVF6dChQw5jr169qu7du6tDhw76/PPPNXnyZK1atUqDBg2SJK1bt05xcXF6+umnJUnPPvusxowZo44dO2r16tV67bXXtG7dOkVGRurs2bMO287rfZKkefPmaevWrZo3b57ee+89/fDDD+rWrZsGDRqkM2fOaPHixZoxY4a++eYb+75vcOZ9zs/7cu3aNXXp0kWvvfaaHnzwQa1atUpLlixRZGSkkpKS7P2GDBmi4cOH6/7779dnn32m+fPn6+DBg4qMjNSpU6ecft+AImcAlDoDBgwwZcqUcWhr27atkWT+85//WI7Nzs42mZmZJjY21kgy+/bts782ceJE8/u/NmrWrGn8/PzM8ePH7W1Xrlwxt912mxkyZIi9bdOmTUaS2bRpk0OdksyKFSscttm1a1fToEED+/N58+YZSWbt2rUO/YYMGWIkmffff9/ymG7se/ny5SYzM9NcvnzZbN682dStW9d4enqaffv2maSkJOPl5WVeeOEFh7Hp6ekmNDTUPPbYYznqXrx4cY593ZijM2fO2NsSEhKMJPPcc8859N2xY4eRZF5++WV7W17vU2JiopFkmjRpYrKysuzts2fPNpJM9+7dHfoPHz7cSDKpqam5zonV+5zf92Xp0qVGklm4cGGu+zDGmLi4OCPJvP322w7tP/30k/H39zejR4/OcyxQUrCyBPyBBAUFqUOHDjnajx49qj59+ig0NFSenp7y9vZW27ZtJSlf3xa76667VKNGDftzPz8/1a9f3+H0Vl5sNluOlY0777zTYWxsbKzKlSunzp07O/Tr3bv3Tbf/W7169ZK3t7cCAgLUpk0bZWVlaeXKlbrzzjv19ddf69q1a+rfv7+uXbtmf/j5+alt27a5fovv4Ycfztd+N23aJOn66a3fatmypSIiIvSf//zHoT2v90mSunbtKg+P//urOyIiQpL0wAMPOPS70f7bFR5n3uf8vC9r166Vn5+f/XRubr788kvZbDb17dvXYV5DQ0PVpEmTYvl2JOAsLvAG/kDCwsJytF28eFFRUVHy8/PT66+/rvr16ysgIEA//fST/vznP+vKlSs33W7FihVztPn6+uZrbEBAgPz8/HKM/fXXX+3Pz507p5CQkBxjc2uzMn36dHXo0EGenp4KDg5W9erV7a/dOB30pz/9Kdexvw0oN+rO77f6zp07Jyn3+a9SpUqOUJlbvxtuu+02h+c+Pj6W7Tfm0dn3OT/vy5kzZ1SlSpUcc/Nbp06dkjEmz/eqdu3aeY4FSgrCEvAHkts9kjZu3KiTJ08qJibGvsogSRcuXCjCyqxVrFhRO3fuzNGekpLi1HZq166d59f4g4ODJUkrV65UzZo1b7otZ+43dSNMJicn5/g24cmTJ+37Lsi288sV73OlSpX07bffKjs7O8/AFBwcLJvNpi1btsjX1zfH67m1ASUNp+GAP7gbH8y//9B69913i6OcXLVt21bp6elau3atQ/tHH31UaPvo1KmTvLy8dOTIEbVo0SLXR0HdOKX273//26F9165dSkhI0H333XdLteeHK97nLl266Ndff7X8NuKDDz4oY4x+/vnnXOf0jjvuKPD+gaLCyhLwBxcZGamgoCANHTpUEydOlLe3t5YtW6Z9+/YVd2l2AwYM0KxZs9S3b1+9/vrrqlu3rtauXauvv/5aUs5TZAURHh6uKVOmaPz48Tp69Kg6d+6soKAgnTp1Sjt37lSZMmU0efLkAm27QYMGeuaZZ/SPf/xDHh4e6tKli44dO6ZXXnlF1atX14gRI265/ptxxfvcu3dvvf/++xo6dKgOHz6s9u3bKzs7Wzt27FBERIQef/xx3XPPPXrmmWf01FNPaffu3WrTpo3KlCmj5ORkffvtt7rjjjv07LPPFuKRAoWPlSXgD65ixYr66quvFBAQoL59+2rgwIEqW7asli9fXtyl2ZUpU0YbN25Uu3btNHr0aD388MNKSkrS/PnzJanQflJk3LhxWrlypX788UcNGDBAnTp10ujRo3X8+HG1adPmlra9YMECvfnmm1qzZo0efPBBjR8/XtHR0dq2bVuu13wVNle8z15eXlqzZo3GjRunVatW6aGHHlL//v317bffOpzKfPfddzV37lxt3rxZjz/+uB544AG9+uqrunTpklq2bFkYhwe4FD93AsBtTZ06VRMmTFBSUlKB7ywOADfDaTgAbmHu3LmSpIYNGyozM1MbN27UnDlz1LdvX4ISAJciLAFwCwEBAZo1a5aOHTumjIwM1ahRQ2PGjLH/vAgAuAqn4QAAACxwgTcAAIAFwhIAAIAFwhIAAIAFLvAuBNnZ2Tp58qTKlSvnkp8pAAAAhc8Yo/T09Jv+xiFhqRCcPHnS4Qc5AQCA+/jpp58sb0FCWCoE5cqVk3R9svP7K+QAAKB4paWlqXr16vbP8bwQlgrBjVNv5cuXJywBAOBmbnYJDRd4AwAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWHC7sDR//nzVqlVLfn5+at68ubZs2WLZPzY2Vs2bN5efn59q166td955J8++H330kWw2m3r06FHIVQMAAHflVmFp+fLlGj58uMaPH6/4+HhFRUWpS5cuSkpKyrV/YmKiunbtqqioKMXHx+vll1/WsGHD9Mknn+Toe/z4cY0aNUpRUVGuPgwAAOBGbMYYU9xF5FerVq3UrFkzLViwwN4WERGhHj16aNq0aTn6jxkzRqtXr1ZCQoK9bejQodq3b5/i4uLsbVlZWWrbtq2eeuopbdmyRRcuXNBnn32W77rS0tIUGBio1NRUlS9fvmAHBwAAilR+P7/dZmXp6tWr2rNnj6Kjox3ao6OjtW3btlzHxMXF5ejfqVMn7d69W5mZmfa2KVOmqFKlSho0aFDhFw4AANyaV3EXkF9nz55VVlaWQkJCHNpDQkKUkpKS65iUlJRc+1+7dk1nz55VWFiYtm7dqkWLFmnv3r35riUjI0MZGRn252lpafk/EAAA4FbcZmXpBpvN5vDcGJOj7Wb9b7Snp6erb9++WrhwoYKDg/Ndw7Rp0xQYGGh/VK9e3YkjAAAA7sRtVpaCg4Pl6emZYxXp9OnTOVaPbggNDc21v5eXlypWrKiDBw/q2LFj6tatm/317OxsSZKXl5cOHz6sOnXq5NjuuHHjNHLkSPvztLQ0AhMAAKWU24QlHx8fNW/eXBs2bFDPnj3t7Rs2bNBDDz2U65jWrVvriy++cGhbv369WrRoIW9vbzVs2FAHDhxweH3ChAlKT0/X3//+9zwDkK+vr3x9fW/xiAAAgDtwm7AkSSNHjlS/fv3UokULtW7dWv/85z+VlJSkoUOHSrq+4vPzzz9r6dKlkq5/823u3LkaOXKkBg8erLi4OC1atEgffvihJMnPz0+NGzd22EeFChUkKUc7AAD4Y3KrsNSrVy+dO3dOU6ZMUXJysho3bqw1a9aoZs2akqTk5GSHey7VqlVLa9as0YgRIzRv3jxVqVJFc+bM0cMPP1xchwAAANyMW91nqaTiPksAALifUnefJQAAgOJAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALDgdmFp/vz5qlWrlvz8/NS8eXNt2bLFsn9sbKyaN28uPz8/1a5dW++8847D6wsXLlRUVJSCgoIUFBSk+++/Xzt37nTlIQAAADfiVmFp+fLlGj58uMaPH6/4+HhFRUWpS5cuSkpKyrV/YmKiunbtqqioKMXHx+vll1/WsGHD9Mknn9j7xMTEqHfv3tq0aZPi4uJUo0YNRUdH6+effy6qwwIAACWYzRhjiruI/GrVqpWaNWumBQsW2NsiIiLUo0cPTZs2LUf/MWPGaPXq1UpISLC3DR06VPv27VNcXFyu+8jKylJQUJDmzp2r/v3756uutLQ0BQYGKjU1VeXLl3fyqAAAQHHI7+e326wsXb16VXv27FF0dLRDe3R0tLZt25brmLi4uBz9O3XqpN27dyszMzPXMZcvX1ZmZqZuu+22wikcAAC4Na/iLiC/zp49q6ysLIWEhDi0h4SEKCUlJdcxKSkpufa/du2azp49q7CwsBxjxo4dq6pVq+r+++/Ps5aMjAxlZGTYn6elpTlzKAAAwI24zcrSDTabzeG5MSZH283659YuSTNmzNCHH36oTz/9VH5+fnluc9q0aQoMDLQ/qlev7swhAAAAN5KvlaU5c+bke4PDhg0rcDFWgoOD5enpmWMV6fTp0zlWj24IDQ3Ntb+Xl5cqVqzo0P7WW29p6tSp+uabb3TnnXda1jJu3DiNHDnS/jwtLY3ABABAKZWvsDRr1iyH52fOnNHly5dVoUIFSdKFCxcUEBCgypUruyws+fj4qHnz5tqwYYN69uxpb9+wYYMeeuihXMe0bt1aX3zxhUPb+vXr1aJFC3l7e9vb/va3v+n111/X119/rRYtWty0Fl9fX/n6+hbwSAAAgDvJ12m4xMRE++ONN97QXXfdpYSEBJ0/f17nz59XQkKCmjVrptdee82lxY4cOVLvvfeeFi9erISEBI0YMUJJSUkaOnSopOsrPr/9BtvQoUN1/PhxjRw5UgkJCVq8eLEWLVqkUaNG2fvMmDFDEyZM0OLFixUeHq6UlBSlpKTo4sWLLj0WAADgJoyTateubb777rsc7bt37zbh4eHObs5p8+bNMzVr1jQ+Pj6mWbNmJjY21v7agAEDTNu2bR36x8TEmKZNmxofHx8THh5uFixY4PB6zZo1jaQcj4kTJ+a7ptTUVCPJpKam3sqhAQCAIpTfz2+n77MUEBCgmJgYtWzZ0qF9586dateunS5fvlw4Kc6NcJ8lAADcj8vus3Tfffdp8ODB2r17t/2bZbt379aQIUMsv24PAADgjpwOS4sXL1bVqlXVsmVL+fn5ydfXV61atVJYWJjee+89V9QIAABQbJy6KaUxRpcvX9bKlSv1888/KyEhQcYYRUREqH79+q6qEQAAoNg4HZbq1aungwcPql69eqpXr56r6gIAACgRnDoN5+HhoXr16uncuXOuqgcAAKBEcfqapRkzZuivf/2rvv/+e1fUAwAAUKI4feuAoKAgXb58WdeuXZOPj4/8/f0dXj9//nyhFugOuHUAAADuJ7+f305dsyRJs2fPvpW6AAAA3IrTYWnAgAGuqAMAAKBEcjos/daVK1eUmZnp0MZpKAAAUJo4fYH3pUuX9Pzzz6ty5coqW7asgoKCHB4AAAClidNhafTo0dq4caPmz58vX19fvffee5o8ebKqVKmipUuXuqJGAACAYuP0abgvvvhCS5cuVbt27TRw4EBFRUWpbt26qlmzppYtW6YnnnjCFXUCAAAUC6dXls6fP69atWpJun590o1bBdx7773avHlz4VYHAABQzJwOS7Vr19axY8ckSY0aNdKKFSskXV9xqlChQmHWBgAAUOycDktPPfWU9u3bJ0kaN26c/dqlESNG6K9//WuhFwgAAFCcnL6D9+8lJSVp9+7dqlOnjpo0aVJYdbkV7uANAID7cdkdvC9fvqyAgAD78xo1aqhGjRoFqxIAAKCEczosVahQQS1atFC7du3Utm1b3XvvvSpTpowragMAACh2Tl+zFBsbq+7du+u7777To48+qqCgIN19990aO3as1q5d64oaAQAAis0tXbOUlZWlXbt26Z133tGyZcuUnZ2trKyswqzPLXDNEgAA7sdl1yxJ0g8//KCYmBjFxsYqJiZGmZmZ6tatm9q2bVvgggEAAEoip8NSaGioMjMz1aFDB7Vr104vv/yy7rjjDlfUBgAAUOycvmYpNDRUFy9eVFJSkpKSknTixAldvHjRFbUBAAAUO6fD0t69e3Xq1CmNHz9e165d0yuvvKJKlSqpVatWGjt2rCtqBAAAKDa3dIH3+fPnFRMTo88//1wffPABF3hzgTcAAG7DZRd4r1q1SjExMYqJidHBgwdVsWJFRUVFadasWWrfvv0tFQ0AAFDSOL2yVLlyZbVp00bt2rVTu3bt1LhxY1fV5jZYWQIAwP24bGXp9OnTt1QYAACAO3H6Am9JOnLkiCZMmKDevXvbw9O6det08ODBQi0OAACguBXo507uuOMO7dixQ59++qn9tgH79+/XxIkTC71AAACA4uR0WBo7dqxef/11bdiwQT4+Pvb29u3bKy4urlCLAwAAKG5Oh6UDBw6oZ8+eOdorVaqkc+fOFUpRAAAAJYXTYalChQpKTk7O0R4fH6+qVasWSlEAAAAlhdNhqU+fPhozZoxSUlJks9mUnZ2trVu3atSoUerfv78ragQAACg2ToelN954QzVq1FDVqlV18eJFNWrUSG3atFFkZKTGjx/vihoBAACKTYF/7uTIkSOKj49Xdna2mjZtqnr16hV2bW6Dm1ICAOB+XHZTyhvq1KmjOnXq2J9/+umnmjRpkvbv31/QTQIAAJQ4Tp2GW7hwoR599FH16dNHO3bskCRt3LhRTZs2Vd++fdW6dWuXFAkAAFBc8h2W3nrrLf3lL39RYmKiPv/8c3Xo0EFTp07VY489ph49eigpKUnvvvuuK2sFAAAocvk+Dbdo0SK98847GjhwoGJiYtShQwdt3LhR//vf/1ShQgUXlggAAFB88r2ydPz4cd1///2SpHbt2snb21tvvPEGQQkAAJRq+Q5Lv/76q/z8/OzPfXx8VKlSJZcUBQAAUFI49W249957T2XLlpUkXbt2TUuWLFFwcLBDn2HDhhVedQAAAMUs3/dZCg8Pl81ms96YzaajR48WSmHuhPssAQDgfgr9PkvHjh0rjLoAAADcitM/dwIAAPBHQlgCAACwQFgCAACwQFgCAACwQFgCAACwUKCwdOTIEU2YMEG9e/fW6dOnJUnr1q3TwYMHC7U4AACA4uZ0WIqNjdUdd9yhHTt26NNPP9XFixclSfv379fEiRMLvUAAAIDi5HRYGjt2rF5//XVt2LBBPj4+9vb27dsrLi6uUIsDAAAobk6HpQMHDqhnz5452itVqqRz584VSlEAAAAlhdNhqUKFCkpOTs7RHh8fr6pVqxZKUQAAACWF02GpT58+GjNmjFJSUmSz2ZSdna2tW7dq1KhR6t+/vytqBAAAKDZOh6U33nhDNWrUUNWqVXXx4kU1atRIbdq0UWRkpCZMmOCKGh3Mnz9ftWrVkp+fn5o3b64tW7ZY9o+NjVXz5s3l5+en2rVr65133snR55NPPlGjRo3k6+urRo0aadWqVa4qHwAAuBmnw5K3t7eWLVumH3/8UStWrNC///1v/fDDD/rXv/4lT09PV9Rot3z5cg0fPlzjx49XfHy8oqKi1KVLFyUlJeXaPzExUV27dlVUVJTi4+P18ssva9iwYfrkk0/sfeLi4tSrVy/169dP+/btU79+/fTYY49px44dLj0WAADgHmzGGOPMgNjYWLVt29ZV9Vhq1aqVmjVrpgULFtjbIiIi1KNHD02bNi1H/zFjxmj16tVKSEiwtw0dOlT79u2zf3OvV69eSktL09q1a+19OnfurKCgIH344Yf5qistLU2BgYFKTU1V+fLlC3p4Ofxy6aouXb1WaNsDAMBdVQjwUVlfr0LdZn4/v53ea8eOHRUaGqo+ffqob9++aty48S0Vml9Xr17Vnj17NHbsWIf26Ohobdu2LdcxcXFxio6Odmjr1KmTFi1apMzMTHl7eysuLk4jRozI0Wf27Nl51pKRkaGMjAz787S0NCePJn/+tv6wPtiR+6oZAAB/JFN73qE+rWoUy76dDksnT57URx99pA8//FAzZsxQ48aN1bdvX/Xp00fVqlVzRY2SpLNnzyorK0shISEO7SEhIUpJScl1TEpKSq79r127prNnzyosLCzPPnltU5KmTZumyZMnF/BI8s/bwyZfL36RBgAAz2L8OHQ6LAUHB+v555/X888/r8TERH3wwQdaunSpXn75ZbVp00YbN250RZ12NpvN4bkxJkfbzfr/vt3ZbY4bN04jR460P09LS1P16tVvXryTJj/UWJMfKpqVOwAAkLtbOvlXq1YtjR07Vk2aNNErr7yi2NjYwqorh+DgYHl6euZY8Tl9+nSOlaEbQkNDc+3v5eWlihUrWvbJa5uS5OvrK19f34IcBgAAcDMFXtTaunWrnnvuOYWFhalPnz66/fbb9eWXXxZmbQ58fHzUvHlzbdiwwaF9w4YNioyMzHVM69atc/Rfv369WrRoIW9vb8s+eW0TAAD8wRgnjRs3zoSHhxsfHx/TtWtXs2zZMnPp0iVnN1MgH330kfH29jaLFi0yhw4dMsOHDzdlypQxx44dM8YYM3bsWNOvXz97/6NHj5qAgAAzYsQIc+jQIbNo0SLj7e1tVq5cae+zdetW4+npad58802TkJBg3nzzTePl5WW2b9+e77pSU1ONJJOamlp4BwsAAFwqv5/fTp+Gi4mJ0ahRo9SrVy8FBwcXfnqz0KtXL507d05TpkxRcnKyGjdurDVr1qhmzZqSpOTkZId7LtWqVUtr1qzRiBEjNG/ePFWpUkVz5szRww8/bO8TGRmpjz76SBMmTNArr7yiOnXqaPny5WrVqlWRHhsAACiZnL7PEnJy1X2WAACA6xTqfZZWr16tLl26yNvbW6tXr7bs2717d+cqBQAAKMHytbLk4eGhlJQUVa5cWR4eeV8TbrPZlJWVVagFugNWlgAAcD+FurKUnZ2d638DAACUdk7fOmDp0qUOP/Vxw9WrV7V06dJCKQoAAKCkcPoCb09PTyUnJ6ty5coO7efOnVPlypU5DcdpOAAA3EJ+P7+dXlkyefwUyIkTJxQYGOjs5gAAAEq0fN9nqWnTprLZbLLZbLrvvvvk5fV/Q7OyspSYmKjOnTu7pEgAAIDiku+w1KNHD0nS3r171alTJ5UtW9b+mo+Pj8LDwx1u9ggAAFAa5DssTZw4UZIUHh6uXr16yc/Pz2VFAQAAlBRO/9zJgAEDXFEHAABAieR0WMrKytKsWbO0YsUKJSUl6erVqw6vnz9/vtCKAwAAKG5Ofxtu8uTJmjlzph577DGlpqZq5MiR+vOf/ywPDw9NmjTJBSUCAAAUH6fD0rJly7Rw4UKNGjVKXl5e6t27t9577z29+uqr2r59uytqBAAAKDZOh6WUlBTdcccdkqSyZcsqNTVVkvTggw/qq6++KtzqAAAAipnTYalatWpKTk6WJNWtW1fr16+XJO3atUu+vr6FWx0AAEAxczos9ezZU//5z38kSS+++KJeeeUV1atXT/3799fAgQMLvUAAAIDi5PRvw/3e9u3btW3bNtWtW1fdu3cvrLrcCr8NBwCA+8nv57fTtw74vbvvvlt33333rW4GAACgRMpXWFq9enW+N/hHXV0CAAClU77C0o3fhbsZm82mrKysW6kHAACgRMlXWMrOznZ1HQAAACWS09+GAwAA+CNx+gLvKVOmWL7+6quvFrgYAACAksbpsLRq1SqH55mZmUpMTJSXl5fq1KlDWAIAAKWK02EpPj4+R1taWpqefPJJ9ezZs1CKAgAAKCkK5Zql8uXLa8qUKXrllVcKY3MAAAAlRqFd4H3hwgX7j+oCAACUFk6fhpszZ47Dc2OMkpOT9a9//UudO3cutMIAAABKAqfD0qxZsxyee3h4qFKlShowYIDGjRtXaIUBAACUBE6HpcTERFfUAQAAUCJxU0oAAAALTq8s/frrr/rHP/6hTZs26fTp0zl+CuW7774rtOIAAACKm9NhaeDAgdqwYYMeeeQRtWzZUjabzRV1AQAAlAhOh6WvvvpKa9as0T333OOKegAAAEoUp69Zqlq1qsqVK+eKWgAAAEocp8PS22+/rTFjxuj48eOuqAcAAKBEcfo0XIsWLfTrr7+qdu3aCggIkLe3t8Pr58+fL7TiAAAAipvTYal37976+eefNXXqVIWEhHCBNwAAKNWcDkvbtm1TXFycmjRp4op6AAAAShSnr1lq2LChrly54opaAAAAShynw9Kbb76pl156STExMTp37pzS0tIcHgAAAKWJzRhjnBng4XE9X/3+WiVjjGw2m7KysgqvOjeRlpamwMBApaamqnz58sVdDgAAyIf8fn47fc3Spk2bbqkwAAAAd+J0WGrbtq0r6gAAACiRnA5Lmzdvtny9TZs2BS4GAACgpHE6LLVr1y5H22+vX/ojXrMEAABKL6e/DffLL784PE6fPq1169bpT3/6k9avX++KGgEAAIqN0ytLgYGBOdo6duwoX19fjRgxQnv27CmUwgAAAEoCp1eW8lKpUiUdPny4sDYHAABQIji9srR//36H58YYJScn68033+QnUAAAQKnjdFi66667ZLPZ9Pt7Wd59991avHhxoRUGAABQEjgdlhITEx2ee3h4qFKlSvLz8yu0ogAAAEoKp8NSzZo1XVEHAABAiZTvC7w3btyoRo0a5fpjuampqbr99tu1ZcuWQi0OAACguOU7LM2ePVuDBw/O9YfmAgMDNWTIEM2cObNQiwMAAChu+Q5L+/btU+fOnfN8PTo6mnssAQCAUiffYenUqVPy9vbO83UvLy+dOXOmUIrKzS+//KJ+/fopMDBQgYGB6tevny5cuGA5xhijSZMmqUqVKvL391e7du108OBB++vnz5/XCy+8oAYNGiggIEA1atTQsGHDlJqa6rLjAAAA7iXfYalq1ao6cOBAnq/v379fYWFhhVJUbvr06aO9e/dq3bp1Wrdunfbu3at+/fpZjpkxY4ZmzpypuXPnateuXQoNDVXHjh2Vnp4uSTp58qROnjypt956SwcOHNCSJUu0bt06DRo0yGXHAQAA3IvN/P6GSXl44YUXFBMTo127duW4TcCVK1fUsmVLtW/fXnPmzCn0IhMSEtSoUSNt375drVq1kiRt375drVu31g8//KAGDRrkGGOMUZUqVTR8+HCNGTNGkpSRkaGQkBBNnz5dQ4YMyXVfH3/8sfr27atLly7Jyyt/XxZMS0tTYGCgUlNTc72mCwAAlDz5/fzO98rShAkTdP78edWvX18zZszQ559/rtWrV2v69Olq0KCBzp8/r/HjxxdK8b8XFxenwMBAe1CSrt8EMzAwUNu2bct1TGJiolJSUhQdHW1v8/X1Vdu2bfMcI8k+YVZBKSMjQ2lpaQ4PAABQOuX7PkshISHatm2bnn32WY0bN85+B2+bzaZOnTpp/vz5CgkJcUmRKSkpqly5co72ypUrKyUlJc8xN+r+rZCQEB0/fjzXMefOndNrr72W56rTDdOmTdPkyZPzUzoAAHBzTv2Qbs2aNbVmzRqdPXtWO3bs0Pbt23X27FmtWbNG4eHhTu980qRJstlslo/du3dLuh7Kfs8Yk2v7b/3+9bzGpKWl6YEHHlCjRo00ceJEy22OGzdOqamp9sdPP/10s0MFAABuyuk7eEtSUFCQ/vSnP93yzp9//nk9/vjjln3Cw8O1f/9+nTp1KsdrZ86cyXM1KzQ0VNL1FabfXnh++vTpHGPS09PVuXNnlS1bVqtWrbL81p90/XSer6+vZR8AAFA6FCgsFZbg4GAFBwfftF/r1q2VmpqqnTt3qmXLlpKkHTt2KDU1VZGRkbmOqVWrlkJDQ7VhwwY1bdpUknT16lXFxsZq+vTp9n5paWnq1KmTfH19tXr1an7jDgAAOHDqNFxxiYiIUOfOnTV48GBt375d27dv1+DBg/Xggw86fBOuYcOGWrVqlaTrp9+GDx+uqVOnatWqVfr+++/15JNPKiAgQH369JF0fUUpOjpaly5d0qJFi5SWlqaUlBSlpKQoKyurWI4VAACULMW6suSMZcuWadiwYfZvt3Xv3l1z58516HP48GGHG0qOHj1aV65c0XPPPadffvlFrVq10vr161WuXDlJ0p49e7Rjxw5JUt26dR22lZiYWKDrsAAAQOmS7/ssIW/cZwkAAPdT6PdZAgAA+CMiLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFggLAEAAFhwm7D0yy+/qF+/fgoMDFRgYKD69eunCxcuWI4xxmjSpEmqUqWK/P391a5dOx08eDDPvl26dJHNZtNnn31W+AcAAADcktuEpT59+mjv3r1at26d1q1bp71796pfv36WY2bMmKGZM2dq7ty52rVrl0JDQ9WxY0elp6fn6Dt79mzZbDZXlQ8AANyUV3EXkB8JCQlat26dtm/frlatWkmSFi5cqNatW+vw4cNq0KBBjjHGGM2ePVvjx4/Xn//8Z0nS//t//08hISH64IMPNGTIEHvfffv2aebMmdq1a5fCwsKK5qAAAIBbcIuVpbi4OAUGBtqDkiTdfffdCgwM1LZt23Idk5iYqJSUFEVHR9vbfH191bZtW4cxly9fVu/evTV37lyFhobmq56MjAylpaU5PAAAQOnkFmEpJSVFlStXztFeuXJlpaSk5DlGkkJCQhzaQ0JCHMaMGDFCkZGReuihh/Jdz7Rp0+zXTgUGBqp69er5HgsAANxLsYalSZMmyWazWT52794tSbleT2SMuel1Rr9//bdjVq9erY0bN2r27NlO1T1u3DilpqbaHz/99JNT4wEAgPso1muWnn/+eT3++OOWfcLDw7V//36dOnUqx2tnzpzJsXJ0w41TaikpKQ7XIZ0+fdo+ZuPGjTpy5IgqVKjgMPbhhx9WVFSUYmJict22r6+vfH19LesGAAClQ7GGpeDgYAUHB9+0X+vWrZWamqqdO3eqZcuWkqQdO3YoNTVVkZGRuY6pVauWQkNDtWHDBjVt2lSSdPXqVcXGxmr69OmSpLFjx+rpp592GHfHHXdo1qxZ6tat260cGgAAKCXc4ttwERER6ty5swYPHqx3331XkvTMM8/owQcfdPgmXMOGDTVt2jT17NlTNptNw4cP19SpU1WvXj3Vq1dPU6dOVUBAgPr06SPp+upTbhd116hRQ7Vq1SqagwMAACWaW4QlSVq2bJmGDRtm/3Zb9+7dNXfuXIc+hw8fVmpqqv356NGjdeXKFT333HP65Zdf1KpVK61fv17lypUr0toBAID7shljTHEX4e7S0tIUGBio1NRUlS9fvrjLAQAA+ZDfz2+3uHUAAABAcSEsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWCAsAQAAWPAq7gJKA2OMJCktLa2YKwEAAPl143P7xud4XghLhSA9PV2SVL169WKuBAAAOCs9PV2BgYF5vm4zN4tTuKns7GydPHlS5cqVk81mK7TtpqWlqXr16vrpp59Uvnz5QtsucmKuiwbzXDSY56LBPBcNV86zMUbp6emqUqWKPDzyvjKJlaVC4OHhoWrVqrls++XLl+d/xCLCXBcN5rloMM9Fg3kuGq6aZ6sVpRu4wBsAAMACYQkAAMACYakE8/X11cSJE+Xr61vcpZR6zHXRYJ6LBvNcNJjnolES5pkLvAEAACywsgQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsFTM5s+fr1q1asnPz0/NmzfXli1bLPvHxsaqefPm8vPzU+3atfXOO+8UUaXuzZl5/vTTT9WxY0dVqlRJ5cuXV+vWrfX1118XYbXuzdk/0zds3bpVXl5euuuuu1xbYCnh7DxnZGRo/Pjxqlmzpnx9fVWnTh0tXry4iKp1X87O87Jly9SkSRMFBAQoLCxMTz31lM6dO1dE1bqnzZs3q1u3bqpSpYpsNps+++yzm44p8s9Cg2Lz0UcfGW9vb7Nw4UJz6NAh8+KLL5oyZcqY48eP59r/6NGjJiAgwLz44ovm0KFDZuHChcbb29usXLmyiCt3L87O84svvmimT59udu7caX788Uczbtw44+3tbb777rsirtz9ODvXN1y4cMHUrl3bREdHmyZNmhRNsW6sIPPcvXt306pVK7NhwwaTmJhoduzYYbZu3VqEVbsfZ+d5y5YtxsPDw/z97383R48eNVu2bDG333676dGjRxFX7l7WrFljxo8fbz755BMjyaxatcqyf3F8FhKWilHLli3N0KFDHdoaNmxoxo4dm2v/0aNHm4YNGzq0DRkyxNx9990uq7E0cHaec9OoUSMzefLkwi6t1CnoXPfq1ctMmDDBTJw4kbCUD87O89q1a01gYKA5d+5cUZRXajg7z3/7299M7dq1HdrmzJljqlWr5rIaS5v8hKXi+CzkNFwxuXr1qvbs2aPo6GiH9ujoaG3bti3XMXFxcTn6d+rUSbt371ZmZqbLanVnBZnn38vOzlZ6erpuu+02V5RYahR0rt9//30dOXJEEydOdHWJpUJB5nn16tVq0aKFZsyYoapVq6p+/foaNWqUrly5UhQlu6WCzHNkZKROnDihNWvWyBijU6dOaeXKlXrggQeKouQ/jOL4LOSHdIvJ2bNnlZWVpZCQEIf2kJAQpaSk5DomJSUl1/7Xrl3T2bNnFRYW5rJ63VVB5vn33n77bV26dEmPPfaYK0osNQoy1//97381duxYbdmyRV5e/HWUHwWZ56NHj+rbb7+Vn5+fVq1apbNnz+q5557T+fPnuW4pDwWZ58jISC1btky9evXSr7/+qmvXrql79+76xz/+URQl/2EUx2chK0vFzGazOTw3xuRou1n/3NrhyNl5vuHDDz/UpEmTtHz5clWuXNlV5ZUq+Z3rrKws9enTR5MnT1b9+vWLqrxSw5k/09nZ2bLZbFq2bJlatmyprl27aubMmVqyZAmrSzfhzDwfOnRIw4YN06uvvqo9e/Zo3bp1SkxM1NChQ4ui1D+Uov4s5J9yxSQ4OFienp45/oVy+vTpHIn5htDQ0Fz7e3l5qWLFii6r1Z0VZJ5vWL58uQYNGqSPP/5Y999/vyvLLBWcnev09HTt3r1b8fHxev755yVd/1A3xsjLy0vr169Xhw4diqR2d1KQP9NhYWGqWrWqAgMD7W0REREyxujEiROqV6+eS2t2RwWZ52nTpumee+7RX//6V0nSnXfeqTJlyigqKkqvv/46q/+FpDg+C1lZKiY+Pj5q3ry5NmzY4NC+YcMGRUZG5jqmdevWOfqvX79eLVq0kLe3t8tqdWcFmWfp+orSk08+qQ8++IDrDfLJ2bkuX768Dhw4oL1799ofQ4cOVYMGDbR37161atWqqEp3KwX5M33PPffo5MmTunjxor3txx9/lIeHh6pVq+bSet1VQeb58uXL8vBw/Fj19PSU9H8rH7h1xfJZ6LJLx3FTN76WumjRInPo0CEzfPhwU6ZMGXPs2DFjjDFjx441/fr1s/e/8XXJESNGmEOHDplFixZx64B8cHaeP/jgA+Pl5WXmzZtnkpOT7Y8LFy4U1yG4DWfn+vf4Nlz+ODvP6enpplq1auaRRx4xBw8eNLGxsaZevXrm6aefLq5DcAvOzvP7779vvLy8zPz5882RI0fMt99+a1q0aGFatmxZXIfgFtLT0018fLyJj483kszMmTNNfHy8/RYNJeGzkLBUzObNm2dq1qxpfHx8TLNmzUxsbKz9tQEDBpi2bds69I+JiTFNmzY1Pj4+Jjw83CxYsKCIK3ZPzsxz27ZtjaQcjwEDBhR94W7I2T/Tv0VYyj9n5zkhIcHcf//9xt/f31SrVs2MHDnSXL58uYirdj/OzvOcOXNMo0aNjL+/vwkLCzNPPPGEOXHiRBFX7V42bdpk+XduSfgstBnD2iAAAEBeuGYJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJwB/WsWPHZLPZtHfvXpft48knn1SPHj1ctn2gNNu8ebO6deumKlWqyGaz6bPPPnN6G8YYvfXWW6pfv758fX1VvXp1TZ061altEJYAuK0nn3xSNpstx6Nz5875Gl+9enUlJyercePGLq4UQEFcunRJTZo00dy5cwu8jRdffFHvvfee3nrrLf3www/64osv1LJlS6e24VXgvQNACdC5c2e9//77Dm2+vr75Guvp6anQ0FBXlAWgEHTp0kVdunTJ8/WrV69qwoQJWrZsmS5cuKDGjRtr+vTpateunSQpISFBCxYs0Pfff68GDRoUuA5WlgC4NV9fX4WGhjo8goKCJEk2m00LFixQly5d5O/vr1q1aunjjz+2j/39abhffvlFTzzxhCpVqiR/f3/Vq1fPIYgdOHBAHTp0kL+/vypWrKhnnnlGFy9etL+elZWlkSNHqkKFCqpYsaJGjx6d49fmjTGaMWOGateuLX9/fzVp0kQrV6504QwBpddTTz2lrVu36qOPPtL+/fv16KOPqnPnzvrvf/8rSfriiy9Uu3Ztffnll6pVq5bCw8P19NNP6/z5807th7AEoFR75ZVX9PDDD2vfvn3q27evevfurYSEhDz7Hjp0SGvXrrX/izQ4OFiSdPnyZXXu3FlBQUHatWuXPv74Y33zzTd6/vnn7ePffvttLV68WIsWLdK3336r8+fPa9WqVQ77mDBhgt5//30tWLBABw8e1IgRI9S3b1/Fxsa6bhKAUujIkSP68MMP9fHHHysqKkp16tTRqFGjdO+999r/kXP06FEdP35cH3/8sZYuXaolS5Zoz549euSRR5zbmUt/phcAXGjAgAHG09PTlClTxuExZcoUY4wxkszQoUMdxrRq1co8++yzxhhjEhMTjSQTHx9vjDGmW7du5qmnnsp1X//85z9NUFCQuXjxor3tq6++Mh4eHiYlJcUYY0xYWJh588037a9nZmaaatWqmYceesgYY8zFixeNn5+f2bZtm8O2Bw0aZHr37l3wiQD+ACSZVatW2Z+vWLHCSMrx/7+Xl5d57LHHjDHGDB482Egyhw8fto/bs2ePkWR++OGHfO+ba5YAuLX27dtrwYIFDm233Xab/b9bt27t8Frr1q3z/Pbbs88+q4cffljfffedoqOj1aNHD0VGRkq6fu1DkyZNVKZMGXv/e+65R9nZ2Tp8+LD8/PyUnJzssD8vLy+1aNHCfiru0KFD+vXXX9WxY0eH/V69elVNmzZ1/uCBP7Ds7Gx5enpqz5498vT0dHitbNmykqSwsDB5eXmpfv369tciIiIkSUlJSfm+jomwBMCtlSlTRnXr1nVqjM1my7W9S5cuOn78uL766it98803uu+++/SXv/xFb731lowxeY7Lq/33srOzJUlfffWVqlat6vBafi9KB3Bd06ZNlZWVpdOnTysqKirXPvfcc4+uXbumI0eOqE6dOpKkH3/8UZJUs2bNfO+La5YAlGrbt2/P8bxhw4Z59q9UqZKefPJJ/fvf/9bs2bP1z3/+U5LUqFEj7d27V5cuXbL33bp1qzw8PFS/fn0FBgYqLCzMYX/Xrl3Tnj177M8bNWokX19fJSUlqW7dug6P6tWrF9YhA6XGxYsXtXfvXvtqcGJiovbu3aukpCTVr19fTzzxhPr3769PP/1UiYmJ2rVrl6ZPn641a9ZIku6//341a9ZMAwcOVHx8vPbs2aMhQ4aoY8eODqtNN8PKEgC3lpGRoZSUFIc2Ly8v+4XZH3/8sVq0aKF7771Xy5Yt086dO7Vo0aJct/Xqq6+qefPmuv3225WRkaEvv/zSvmT/xBNPaOLEiRowYIAmTZqkM2fO6IUXXlC/fv0UEhIi6fr9XN58803Vq1dPERERmjlzpi5cuGDffrly5TRq1CiNGDFC2dnZuvfee5WWlqZt27apbNmyGjBggAtmCHBfu3fvVvv27e3PR44cKUkaMGCAlixZovfff1+vv/66XnrpJf3888+qWLGiWrdura5du0qSPDw89MUXX+iFF15QmzZtVKZMGXXp0kVvv/22c4UU0nVXAFDkBgwYYCTleDRo0MAYc/2C0Hnz5pmOHTsaX19fU7NmTfPhhx/ax//+Au/XXnvNREREGH9/f3PbbbeZhx56yBw9etTef//+/aZ9+/bGz8/P3HbbbWbw4MEmPT3d/npmZqZ58cUXTfny5U2FChXMyJEjTf/+/e0XeBtjTHZ2tvn73/9uGjRoYLy9vU2lSpVMp06dTGxsrGsnC0CB2Yz53U1AAKCUsNlsWrVqFT83AuCWcM0SAACABcISAACABS7wBlBqcZUBgMLAyhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAICF/w9gU/+Rl+PWCAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Complete')\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgvWmycHVcta"
   },
   "source": [
    "## Problem 3 (2 points)\n",
    "\n",
    "Implement DQN with $\\epsilon$-greedy, where $\\epsilon$ is a hyperparameter that you will tune. (You should have already have this code from HW2!)\n",
    "\n",
    "Run DQN+$\\epsilon$-greedy in the combination lock MDP (with turned $\\epsilon$) and plot its learning curve: Cumulative reward v.s. training episode same as in HW2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2NYntq8NVctb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def select_action(state, model, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return np.random.randint(env.action_space.n)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = model(torch.FloatTensor(state).unsqueeze(0))\n",
    "            return q_values.max(1)[1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x64 and 20x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m memory\u001b[38;5;241m.\u001b[39mappend((state, action, next_state, reward, done))\n\u001b[1;32m     53\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m---> 55\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m batch_next_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(batch_next_state)\n\u001b[1;32m     28\u001b[0m batch_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(batch_done)\n\u001b[0;32m---> 30\u001b[0m current_q \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, batch_action\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m max_next_q \u001b[38;5;241m=\u001b[39m model(batch_next_state)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m expected_q \u001b[38;5;241m=\u001b[39m batch_reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m max_next_q \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_done)\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mDQN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x64 and 20x128)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 500\n",
    "episodes = 1000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "\n",
    "# Environment setup\n",
    "env = CombLockMDP()  # Initialize your environment\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = 1 #env.action_space.n -> 1\n",
    "\n",
    "model = DQN(input_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "memory = deque(maxlen=10000)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    transitions = random.sample(memory, batch_size)\n",
    "    batch_state, batch_action, batch_next_state, batch_reward, batch_done = zip(*transitions)\n",
    "\n",
    "    batch_state = torch.FloatTensor(batch_state)\n",
    "    batch_action = torch.LongTensor(batch_action)\n",
    "    batch_reward = torch.FloatTensor(batch_reward)\n",
    "    batch_next_state = torch.FloatTensor(batch_next_state)\n",
    "    batch_done = torch.FloatTensor(batch_done)\n",
    "\n",
    "    current_q = model(batch_state).gather(1, batch_action.unsqueeze(1)).squeeze(1)\n",
    "    max_next_q = model(batch_next_state).max(1)[0]\n",
    "    expected_q = batch_reward + gamma * max_next_q * (1 - batch_done)\n",
    "\n",
    "    loss = nn.MSELoss()(current_q, expected_q)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "cumulative_rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    epsilon = epsilon_end + (epsilon_start - epsilon_end) * np.exp(-1. * episode / epsilon_decay)\n",
    "    \n",
    "    while True:\n",
    "        action = select_action(state, model, epsilon)\n",
    "        next_state, reward, done  = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        memory.append((state, action, next_state, reward, done))\n",
    "        state = next_state\n",
    "        \n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    cumulative_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode}, Total reward: {total_reward}\")\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cumulative_rewards)\n",
    "plt.title('Cumulative Reward vs. Training Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, n_actions)  # Two-layer MLP\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return self.layer2(x)  # Q-values for each action\n",
    "\n",
    "# Hyperparameters (adjust as needed)\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Function for selecting actions with -greedy exploration\n",
    "def select_action(state, policy_net, steps_done):\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    sample = random.random()\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # Ensure state has batch dimension and correct shape\n",
    "            state = state.unsqueeze(0)\n",
    "            q_values = policy_net(state)\n",
    "            action = q_values.argmax(dim=1)\n",
    "            return action.item()\n",
    "    else:\n",
    "        return random.randrange(n_actions)\n",
    "\n",
    "\n",
    "# Named tuple for storing transitions\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "# Replay memory to store and sample transitions\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Initialize the Gridworld environment\n",
    "env = GridworldEnv()\n",
    "\n",
    "# Get the number of actions and observations\n",
    "n_actions = env.action_space.n\n",
    "n_observations = env.observation_space.shape[0]\n",
    "\n",
    "# Initialize Q-networks\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "# Initialize optimizer and replay memory\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=1e-4, amsgrad=True)\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.tensor([[s for s in batch.next_state\n",
    "                                                if s is not None]], device=device).t()\n",
    "    state_batch = torch.tensor([batch.state], device=device).t()\n",
    "    action_batch = torch.tensor([batch.action], device=device).t()\n",
    "    reward_batch = torch.tensor([batch.reward], device=device).t()\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(dim=1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * env.gamma) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_episodes = 200\n",
    "episode_durations = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = torch.tensor(env.reset(), device=device, dtype=torch.float)\n",
    "    for t in count():\n",
    "        action = select_action(state, policy_net, t)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        if not done:\n",
    "            next_state = torch.tensor(observation, device=device, dtype=torch.float)\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, torch.tensor([action], device=device), next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        #     + (1  )\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*0.005 + target_net_state_dict[key]*(1-0.005)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done or t > 200:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plt.plot(episode_durations)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Duration')\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, 128)  # Assuming a scalar state, hence `1` here\n",
    "        self.layer2 = nn.Linear(128, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "\n",
    "# Assuming CombLockMDP is already defined\n",
    "env = CombLockMDP(H=4, A=3, S=3, R=10, seed=0)  # Initialize your CombLockMDP environment\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Since the state in CombLockMDP might be a scalar representing the timestep,\n",
    "# we don't need n_observations like in the gridworld environment\n",
    "policy_net = DQN(n_actions).to(device)\n",
    "target_net = DQN(n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "# Rest of the setup remains mostly the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, policy_net, steps_done, n_actions):\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    if random.random() > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # Assuming state is correctly shaped for the network\n",
    "            q_values = policy_net(state)\n",
    "            action = q_values.max(0)[1].view(1, 1)  # Take max across dimension 0\n",
    "            return action\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    \n",
    "    # Here we need to ensure that the states and next_states are properly formatted\n",
    "    non_final_next_states = torch.cat([torch.tensor(s).unsqueeze(0) for s in batch.next_state if s is not None]).to(device)\n",
    "    state_batch = torch.cat([torch.tensor(s).unsqueeze(0) for s in batch.state]).to(device)\n",
    "    \n",
    "    action_batch = torch.tensor(batch.action, device=device).unsqueeze(-1)\n",
    "    reward_batch = torch.tensor(batch.reward, device=device)\n",
    "\n",
    "    # Compute Q(s_t, a)\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(dim=1).values\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/5929199.1.casaq-gpu-pub/ipykernel_3526258/2964877311.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  non_final_next_states = torch.cat([torch.tensor(s).unsqueeze(0) for s in batch.next_state if s is not None]).to(device)\n",
      "/scratch/5929199.1.casaq-gpu-pub/ipykernel_3526258/2964877311.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_batch = torch.cat([torch.tensor(s).unsqueeze(0) for s in batch.state]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99  # Assuming gamma is defined here for discounting future rewards\n",
    "\n",
    "steps_done = 0  # Initialize steps counter for epsilon decay\n",
    "\n",
    "\n",
    "num_episodes = 10000\n",
    "episode_rewards = []\n",
    "target_update_frequency = 10  # Update target network every 10 episodes\n",
    "\n",
    "memory = ReplayMemory(10000)  # or whatever capacity you prefer\n",
    "\n",
    "episode_durations = []  # Add this line to initialize the list\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    initial_state = env.reset()  # Get the initial state from the environment\n",
    "    state = torch.tensor([initial_state], device=device, dtype=torch.float)  # Ensure it's a tensor\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in count():\n",
    "        action = select_action(state, policy_net, steps_done, n_actions)\n",
    "        observation, reward, done = env.step(action.item())\n",
    "        episode_rewards.append(reward)\n",
    "        total_reward += reward\n",
    "\n",
    "        if not done:\n",
    "            next_state = torch.tensor([observation], device=device, dtype=torch.float)\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, torch.tensor([reward], device=device))\n",
    "        \n",
    "        state = next_state if next_state is not None else torch.tensor([env.reset()], device=device, dtype=torch.float)\n",
    "\n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)  # No error here since episode_durations is now defined\n",
    "            break\n",
    "\n",
    "    # Other code such as updating the target network etc.\n",
    "\n",
    "\n",
    "    # Update the target network every few episodes\n",
    "    if i_episode % target_update_frequency == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15810\n"
     ]
    }
   ],
   "source": [
    "print(i_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_R3hhOMVctb"
   },
   "source": [
    "## Problem 4 (3 points)\n",
    "\n",
    "Implement DQN with RND using a randomly neural network as the target network $f:S\\rightarrow \\mathbb{R}^d$, and use the reward bonus in the form of $\\alpha||\\hat{f}(s)-f(s)||_2^2$. \n",
    "\n",
    "Run DQN+RND in the combination lock MDP (with turned hyperparameters, including $\\alpha$, the replay buffer size, learning rates, etc) and plot its learning curve: Cumulative reward v.s. training episode same as in HW2.\n",
    "\n",
    "An example implementation of DQN+RND can be found [here](https://github.com/orrivlin/MountainCar_DQN_RND)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ElbxmHlGVctb"
   },
   "outputs": [],
   "source": [
    "class PredictorNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PredictorNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class TargetNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TargetNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        for param in self.network.parameters():\n",
    "            param.requires_grad = False  # Freeze the target network\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 4x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Compute intrinsic reward using RND networks\u001b[39;00m\n\u001b[1;32m     23\u001b[0m state_tensor \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 24\u001b[0m target_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m predictor_pred \u001b[38;5;241m=\u001b[39m predictor_net(state_tensor)\n\u001b[1;32m     26\u001b[0m intrinsic_reward \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(predictor_pred, target_pred\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[71], line 25\u001b[0m, in \u001b[0;36mTargetNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/ds598xz/students/ziyechen/.conda/envs/myenv310/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 4x128)"
     ]
    }
   ],
   "source": [
    "# Assuming the DQN setup and ReplayMemory are already defined\n",
    "\n",
    "# Initialize the RND networks\n",
    "state_dim = env.observation_space.shape[0]\n",
    "intrinsic_output_dim = 50  # dimensionality of the RND output\n",
    "predictor_net = PredictorNetwork(state_dim, intrinsic_output_dim).to(device)\n",
    "target_net = TargetNetwork(state_dim, intrinsic_output_dim).to(device)\n",
    "rnd_optimizer = optim.Adam(predictor_net.parameters(), lr=1e-4)\n",
    "\n",
    "alpha = 0.1  # scaling factor for intrinsic reward\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state = torch.tensor([state], device=device, dtype=torch.float)\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in count():\n",
    "        action = select_action(state, policy_net, steps_done, n_actions)\n",
    "        next_state, reward, done = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float)\n",
    "\n",
    "        # Compute intrinsic reward using RND networks\n",
    "        state_tensor = state.float()\n",
    "        target_pred = target_net(state_tensor)\n",
    "        predictor_pred = predictor_net(state_tensor)\n",
    "        intrinsic_reward = alpha * F.mse_loss(predictor_pred, target_pred.detach())\n",
    "        combined_reward = reward + intrinsic_reward\n",
    "\n",
    "        if not done:\n",
    "            next_state_tensor = torch.tensor([next_state], device=device, dtype=torch.float)\n",
    "        else:\n",
    "            next_state_tensor = None\n",
    "\n",
    "        memory.push(state, action, next_state_tensor, combined_reward)\n",
    "        state = next_state_tensor if next_state_tensor is not None else torch.tensor([env.reset()], device=device, dtype=torch.float)\n",
    "\n",
    "        optimize_model()  # Make sure to update the DQN and RND networks accordingly\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    # Update RND predictor network here if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2_XsjYMVctc",
    "outputId": "2868c485-83d3-4f16-c8f3-78c0d0ee28dc"
   },
   "source": [
    "## Problem 5 (1 points)\n",
    "\n",
    "Plot the performance curve of UCBVI, DQN with $\\epsilon$-greedy, and DQN+RND in the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "myenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
